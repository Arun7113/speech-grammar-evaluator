{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97919,"databundleVersionId":11694977,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"e62c2aa9-37f1-4f6e-b48d-a80d27f4709f","_cell_guid":"0942912e-3427-48c4-8820-83a0a9a6009a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-06T18:40:18.697128Z","iopub.execute_input":"2025-04-06T18:40:18.697541Z","iopub.status.idle":"2025-04-06T18:40:19.409777Z","shell.execute_reply.started":"2025-04-06T18:40:18.697509Z","shell.execute_reply":"2025-04-06T18:40:19.408793Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/shl-intern-hiring-assessment/dataset/sample_submission.csv\n/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\n/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_885.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_698.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1176.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1215.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_66.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_386.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1026.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_330.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_72.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_858.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_107.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_820.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_300.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_435.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_550.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_841.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_641.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_290.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_401.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_321.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_20.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_348.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_500.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_735.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_888.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_959.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_276.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1323.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1089.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1289.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_29.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_676.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_811.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_762.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1183.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1297.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_709.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_281.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_308.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1054.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_662.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_525.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_633.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_274.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_922.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_683.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1275.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_541.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_113.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_665.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_543.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1012.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_759.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_225.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_644.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1035.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1159.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1179.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1048.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_499.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1123.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1116.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_521.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1013.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_198.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1278.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_4.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_165.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_19.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_261.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_998.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_89.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1280.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_971.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_322.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1058.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1068.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_719.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1205.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1315.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1061.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1091.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_75.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_217.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_95.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_159.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_545.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_379.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_137.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1124.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_177.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_180.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_726.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1081.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_519.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_285.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_569.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_800.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_218.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_148.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_408.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1122.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_884.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_488.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_733.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_235.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_286.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_263.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1022.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_656.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1101.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1286.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_287.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1293.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_692.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1190.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1173.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_388.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_767.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1242.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1311.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_540.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_932.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_448.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_949.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_908.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_158.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_172.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_958.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_805.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_746.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_221.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_391.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_21.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1169.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_68.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_529.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_138.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1195.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_580.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_360.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1033.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1240.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_10.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_48.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1193.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1217.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1292.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_282.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_599.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_153.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_564.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1019.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_196.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1115.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_103.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1291.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_690.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_706.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1214.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1138.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_831.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_857.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1267.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_135.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_433.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_556.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_306.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_109.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1256.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_34.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_572.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_487.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_554.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_512.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1317.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_179.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_604.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_882.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_437.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_920.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_546.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1178.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_702.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1243.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_394.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_428.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1321.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_422.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_713.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_320.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_770.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1166.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_151.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_897.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_90.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_581.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_77.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_817.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_694.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1262.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_237.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_765.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1164.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1251.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1032.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_688.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_886.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1129.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_464.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1040.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_711.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_853.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_436.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_538.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_859.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_547.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1266.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_919.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1036.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_796.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_994.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_760.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_315.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1028.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_55.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1284.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_950.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_256.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_359.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_462.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_44.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_753.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_813.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_7.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1100.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1131.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_119.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_59.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_802.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_518.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_12.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_591.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_536.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1082.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_404.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_254.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_990.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_513.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_653.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1177.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_188.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_539.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_289.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_778.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1210.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_946.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_67.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_186.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_600.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1277.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_291.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_602.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1150.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1118.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1106.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1312.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_495.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_265.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_558.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_82.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_61.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_964.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_526.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1285.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_32.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_535.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_110.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1172.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_567.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1325.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_374.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_944.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_327.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_120.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_297.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1212.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_899.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_516.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_441.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_848.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1103.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_346.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_446.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_104.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1236.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_957.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_776.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1163.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_642.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_479.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_940.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1171.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_563.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_773.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_71.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_76.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_905.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_925.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_205.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_345.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_661.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_102.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1136.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1304.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_399.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1126.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1024.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_45.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_812.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_860.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_942.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_414.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_725.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1245.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_275.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_590.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_955.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_478.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_779.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_2.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_447.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_807.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_223.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1268.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_118.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1202.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_549.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1069.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_366.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_743.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_210.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_874.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_705.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_952.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_836.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_396.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1239.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_909.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_583.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1114.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_771.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_989.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1182.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_865.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_278.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_468.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_930.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_314.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_697.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_722.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_674.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1104.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1134.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1043.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_609.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1329.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1153.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_23.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_542.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_592.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_954.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_916.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_244.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_387.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_313.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1252.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_194.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_427.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_93.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1162.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_142.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_708.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_492.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_934.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_826.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_931.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_255.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_654.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_703.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_657.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_5.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_185.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1175.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1120.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1128.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1066.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_80.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_668.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_8.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_763.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_85.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1318.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_303.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_727.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1057.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_469.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_965.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_202.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_127.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_677.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_788.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_904.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_695.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_463.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1075.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_130.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_273.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_489.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_293.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1030.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_970.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_239.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_252.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_311.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_240.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_288.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1226.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_146.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_643.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_675.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_731.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1191.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_52.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_504.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1112.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_875.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_460.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1111.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_736.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1333.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_365.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_937.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_332.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1335.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_681.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_808.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_766.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_700.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1247.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_686.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1313.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_867.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_939.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_917.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_620.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1099.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_339.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1147.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_921.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_484.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_745.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1274.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1326.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_527.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_948.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_870.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_362.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_873.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_482.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1307.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_680.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_140.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1196.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_582.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_17.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_533.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_154.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_963.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_926.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1264.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1102.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_630.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_730.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_317.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_440.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_611.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_69.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_64.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_978.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_494.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_131.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_336.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_105.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_395.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_324.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_358.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_707.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_15.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_63.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_744.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1038.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_167.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_956.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_716.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_334.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_868.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_854.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_245.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_903.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_834.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1110.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_432.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_236.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1208.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_200.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1078.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1200.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_353.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_947.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_212.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_168.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_352.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_445.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_419.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1332.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_701.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_117.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1059.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_790.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_390.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_586.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_226.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_699.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_363.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_988.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_485.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_241.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_481.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_652.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_424.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_483.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1017.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_890.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1065.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_787.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_627.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1290.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_758.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1314.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_272.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_687.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_809.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_312.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_902.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1296.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_147.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_783.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_144.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_373.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_887.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_443.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_350.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_503.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_62.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_402.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1031.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_116.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_693.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_477.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_413.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1025.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_123.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_133.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_647.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1223.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_980.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_755.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_869.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1148.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_685.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_678.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_53.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1184.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_552.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1216.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1185.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_918.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_250.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_721.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_624.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_43.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_889.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_184.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_842.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1125.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_9.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_455.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1160.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_913.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_493.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_704.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_548.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1230.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_961.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_832.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_33.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_896.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_827.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_748.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_658.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_471.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1117.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_270.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_301.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_576.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_649.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1261.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_640.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_636.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1272.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1135.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_74.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_983.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_993.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_480.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1298.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_876.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_794.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_163.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_450.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_514.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_696.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_389.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1008.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1187.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_724.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_490.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_259.wav\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install torch transformers datasets pandas soundfile librosa openai-whisper --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:40:19.411096Z","iopub.execute_input":"2025-04-06T18:40:19.411549Z","iopub.status.idle":"2025-04-06T18:40:33.684946Z","shell.execute_reply.started":"2025-04-06T18:40:19.411525Z","shell.execute_reply":"2025-04-06T18:40:33.683955Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, Audio\n\n# Load train.csv and test.csv\ntrain_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\")\n\n# Add full audio paths\ntrain_df[\"audio_path\"] = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/\" + train_df[\"filename\"]\ntest_df[\"audio_path\"] = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/\" + test_df[\"filename\"]\n\n# Convert labels to class indices (1.0  0, 1.5  1, ..., 5.0  8)\ntrain_df[\"label\"] = (train_df[\"label\"] * 2 - 2).astype(int)\n\n# Create HuggingFace Dataset\ntrain_dataset = Dataset.from_pandas(train_df).cast_column(\"audio_path\", Audio())\ntest_dataset = Dataset.from_pandas(test_df).cast_column(\"audio_path\", Audio())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:40:33.687163Z","iopub.execute_input":"2025-04-06T18:40:33.687448Z","iopub.status.idle":"2025-04-06T18:40:34.329244Z","shell.execute_reply.started":"2025-04-06T18:40:33.687424Z","shell.execute_reply":"2025-04-06T18:40:34.328611Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\n\nprint(\"CUDA Available:\", torch.cuda.is_available())\nprint(\"Current Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:40:34.330204Z","iopub.execute_input":"2025-04-06T18:40:34.330452Z","iopub.status.idle":"2025-04-06T18:40:36.051668Z","shell.execute_reply.started":"2025-04-06T18:40:34.330432Z","shell.execute_reply":"2025-04-06T18:40:36.050901Z"}},"outputs":[{"name":"stdout","text":"CUDA Available: True\nCurrent Device: Tesla T4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from datasets import Dataset, Audio\nimport whisper\n\n# Load datasets\ntrain_dataset = Dataset.from_pandas(train_df).cast_column(\"audio_path\", Audio())\ntest_dataset = Dataset.from_pandas(test_df).cast_column(\"audio_path\", Audio())\n\n# Transcribe (use small model for GPU efficiency)\nmodel = whisper.load_model(\"medium\")\n\ndef transcribe(batch):\n    transcripts = []\n    for audio in batch[\"audio_path\"]:\n        path = audio[\"path\"] if isinstance(audio, dict) else audio\n        print(\"Processing:\", path)  # Debug        \n        result = model.transcribe(audio[\"path\"])\n        transcripts.append(result[\"text\"])\n    batch[\"text\"] = transcripts\n    return batch\n\n# Apply ASR (batched for speed)\ntrain_dataset = train_dataset.map(transcribe, batched=True, batch_size=16)\ntest_dataset = test_dataset.map(transcribe, batched=True, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:40:36.057051Z","iopub.execute_input":"2025-04-06T18:40:36.057259Z","iopub.status.idle":"2025-04-06T20:39:03.138399Z","shell.execute_reply.started":"2025-04-06T18:40:36.057241Z","shell.execute_reply":"2025-04-06T20:39:03.137624Z"}},"outputs":[{"name":"stderr","text":"100%|| 1.42G/1.42G [00:33<00:00, 46.0MiB/s]\n/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\nParameter 'function'=<function transcribe at 0x7c3e66675c60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e175c614599f42fd8ded7d762f6ad72f"}},"metadata":{}},{"name":"stdout","text":"Processing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1261.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_942.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1110.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1024.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_538.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_350.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_64.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_252.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1304.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1230.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_133.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_790.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_947.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_288.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1111.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_771.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1184.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_918.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1030.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1112.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_873.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_539.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_899.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1277.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_649.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_701.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_763.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_952.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_167.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_708.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1245.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_812.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_76.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1296.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_239.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_668.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_17.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_289.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_45.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_657.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_876.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1069.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1318.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_832.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_917.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_802.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_275.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_940.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1120.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_535.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_244.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1134.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_724.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_965.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1031.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1326.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1325.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_273.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1298.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_868.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_964.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_85.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_919.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_303.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_345.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_930.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_817.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1104.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_836.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_946.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1312.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_324.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_913.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_399.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_766.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_748.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1114.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1251.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_59.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_889.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_130.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_297.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_744.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_779.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1210.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_680.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_944.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_8.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1057.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_722.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1036.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_760.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_675.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_62.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_865.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_654.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_743.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_950.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_77.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_916.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1028.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_727.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_146.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_642.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1313.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1208.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_640.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_778.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1025.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_939.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1216.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_934.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_904.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1102.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1150.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_765.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1117.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_685.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1329.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_236.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_90.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_903.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_905.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_736.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_886.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_773.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_43.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_853.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_278.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_948.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_869.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1223.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1038.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_686.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_346.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_988.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_653.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_809.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1043.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_542.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1106.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_643.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1333.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1239.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1264.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_854.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_681.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_711.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_5.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_446.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_827.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_67.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_776.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_93.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_677.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1226.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1136.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_536.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1247.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_61.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_336.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_661.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_788.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1212.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_813.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1118.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_678.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_427.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_755.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_110.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_859.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_957.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1252.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1126.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_699.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1314.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_794.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1129.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_808.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_875.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_842.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1182.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_848.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1040.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_956.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_902.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_441.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_237.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1290.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1162.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_700.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1200.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_147.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_212.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_168.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_240.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_695.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_256.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_443.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_63.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_721.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_636.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_870.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1335.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_707.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_581.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_272.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1284.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1135.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1187.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_480.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_445.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_447.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1191.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1266.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1307.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_270.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1032.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_931.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_71.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_482.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_725.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_301.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_184.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_387.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_730.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_980.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_602.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_874.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1148.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_954.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_185.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_12.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_241.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_697.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_548.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1128.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_582.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_925.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_69.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_896.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_7.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_611.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_82.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_591.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_674.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_753.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_131.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1103.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_961.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_188.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_926.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_921.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_955.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_127.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_327.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_485.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_705.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1147.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_468.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_477.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_395.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1065.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_254.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1017.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1196.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_358.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_716.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1236.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_807.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_490.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_492.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_469.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_890.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_600.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_731.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_339.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_909.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_658.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_117.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1082.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_291.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1066.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_630.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_404.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_334.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_33.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_186.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_693.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_937.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_424.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1262.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_624.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_620.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_142.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_259.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_503.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1125.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1332.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_52.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_558.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_223.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_194.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_362.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1153.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_200.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_479.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_455.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_313.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_15.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1100.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_80.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_887.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_105.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_483.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_796.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_2.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_317.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_963.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_123.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1272.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_315.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1202.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1008.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_787.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1274.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_265.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1268.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_526.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1285.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_460.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_696.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_44.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_478.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_450.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1164.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_245.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_255.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_513.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_504.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_590.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_592.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_389.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_353.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_250.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_432.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_583.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_402.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_312.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_493.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_516.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_373.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_119.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1175.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1160.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_102.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_140.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_205.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_414.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_314.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_374.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1177.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_464.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_518.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_352.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_396.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_332.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_495.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_53.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_463.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_970.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_120.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_293.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_688.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_834.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_440.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_116.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_359.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_74.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_154.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_32.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_413.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1075.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_163.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1171.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_745.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_527.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_202.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_533.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_226.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_552.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_978.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_994.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_365.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1185.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_826.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_860.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_23.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_144.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_586.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_489.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_694.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_704.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_783.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1059.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_549.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_627.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_311.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_118.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_462.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_419.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_983.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1172.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_436.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_687.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_514.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_484.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1131.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_55.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_547.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_652.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_703.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_9.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_563.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1078.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_758.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_647.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_867.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_567.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_471.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_576.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_210.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_993.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_390.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_104.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_366.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_990.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1099.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_609.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_494.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_363.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_481.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_989.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1163.wav\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"530674994f174d57a189568836e86594"}},"metadata":{}},{"name":"stdout","text":"Processing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_706.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_800.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_68.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1267.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_683.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1242.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_908.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_888.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_137.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_770.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_735.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1026.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1214.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1122.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1022.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_726.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1205.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1116.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1240.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_151.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_437.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1217.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_831.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1315.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1323.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1256.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1033.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_858.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_274.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_196.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1193.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_138.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_644.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1012.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1101.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_805.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_709.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1293.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1123.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1048.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_820.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_767.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_841.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1286.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_665.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1311.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_29.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1289.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_177.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_599.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_920.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_971.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1275.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1291.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_320.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_545.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_287.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_172.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_322.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_541.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_148.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1317.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1243.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_348.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_662.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_540.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_733.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1297.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_949.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1035.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_882.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_401.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_113.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_435.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_719.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_698.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_959.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1166.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_543.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_89.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_884.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_19.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_641.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1115.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_811.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_75.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1138.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_66.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_500.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_922.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_656.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_218.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1278.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_525.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_290.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1195.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_572.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1089.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_488.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_759.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_103.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1280.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_153.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_300.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_20.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_10.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1292.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_281.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_261.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1081.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_276.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_159.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1124.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_690.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1061.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_521.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_263.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1068.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_4.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_676.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_165.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_282.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1179.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_217.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_388.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_550.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_499.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1190.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_433.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_885.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_48.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_308.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_746.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1019.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_487.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_198.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_958.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_72.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1321.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1159.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_428.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1058.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_408.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_857.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_692.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_633.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1173.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_554.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_180.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1013.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_386.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_519.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_564.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1054.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_556.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1183.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_306.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_713.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_225.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1091.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_107.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_286.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_546.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_580.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_235.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_109.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_932.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_330.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_569.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_158.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_321.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_360.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_391.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_448.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1215.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_422.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_998.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_702.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_897.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_394.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1169.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_95.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_604.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_221.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_34.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_179.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_21.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1176.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_285.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1178.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_135.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_512.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_529.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_762.wav\nProcessing: /kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_379.wav\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_df_with_text = train_dataset.to_pandas()\ntest_df_with_text = test_dataset.to_pandas()\n\n# Save to CSV\ntrain_df_with_text.to_csv(\"train_transcribed.csv\", index=False)\ntest_df_with_text.to_csv(\"test_transcribed.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:39:03.139449Z","iopub.execute_input":"2025-04-06T20:39:03.139791Z","iopub.status.idle":"2025-04-06T20:40:56.734533Z","shell.execute_reply.started":"2025-04-06T20:39:03.139756Z","shell.execute_reply":"2025-04-06T20:40:56.733751Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_df_with_text[\"label\"] = train_df[\"label\"].values\ntrain_df_with_text.to_csv(\"train_transcribed.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T22:25:18.474207Z","iopub.execute_input":"2025-04-06T22:25:18.474560Z","iopub.status.idle":"2025-04-06T22:26:37.897214Z","shell.execute_reply.started":"2025-04-06T22:25:18.474532Z","shell.execute_reply":"2025-04-06T22:26:37.896230Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"train_df_with_text.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T22:25:08.822855Z","iopub.execute_input":"2025-04-06T22:25:08.823170Z","iopub.status.idle":"2025-04-06T22:25:09.030342Z","shell.execute_reply.started":"2025-04-06T22:25:08.823144Z","shell.execute_reply":"2025-04-06T22:25:09.029602Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"         filename  label                                         audio_path  \\\n0  audio_1261.wav    1.0  {'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...   \n1   audio_942.wav    1.5  {'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...   \n2  audio_1110.wav    1.5  {'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...   \n3  audio_1024.wav    1.5  {'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...   \n4   audio_538.wav    2.0  {'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...   \n\n                                                text  \n0   My favorite hobby is cultivation of plants su...  \n1   The playground looks like very clear and neat...  \n2   ...  \n3   My favorite place is in Andhra Pradesh. It is...  \n4   my favorite places my favorite places my expe...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n      <th>audio_path</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_1261.wav</td>\n      <td>1.0</td>\n      <td>{'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...</td>\n      <td>My favorite hobby is cultivation of plants su...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_942.wav</td>\n      <td>1.5</td>\n      <td>{'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...</td>\n      <td>The playground looks like very clear and neat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_1110.wav</td>\n      <td>1.5</td>\n      <td>{'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1024.wav</td>\n      <td>1.5</td>\n      <td>{'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...</td>\n      <td>My favorite place is in Andhra Pradesh. It is...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_538.wav</td>\n      <td>2.0</td>\n      <td>{'bytes': b'RIFFzU\\x1d\\x00WAVEfmt \\x10\\x00\\x00...</td>\n      <td>my favorite places my favorite places my expe...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import BertTokenizer, TrainingArguments, Trainer\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\n# =============================================\n# 1. Prepare Data from Existing Transcripts\n# =============================================\n# Verify we have the transcripts\nprint(\"Sample training texts:\", train_dataset[\"text\"][:2])\nprint(\"Sample labels:\", train_dataset[\"label\"][:2])\n\n# =============================================\n# 2. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_dataset = train_dataset.map(tokenize, batched=True)\ntest_dataset = test_dataset.map(tokenize, batched=True)\n\n# Set format for PyTorch\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. Custom BERT Model with Frozen Weights\n# =============================================\nfrom transformers import BertPreTrainedModel, BertModel\nimport torch.nn as nn\n\nclass FrozenBertForGrammarScoring(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n        \n        # Freeze all BERT layers\n        for param in self.bert.parameters():\n            param.requires_grad = False\n            \n        # Unfreeze the last 2 layers and pooler\n        for layer in self.bert.encoder.layer[-2:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        for param in self.bert.pooler.parameters():\n            param.requires_grad = True\n            \n        # Classification head (9 classes: 1.0-5.0 in 0.5 steps)\n        self.classifier = nn.Sequential(\n            nn.Linear(config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 9)\n        )\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        logits = self.classifier(pooled_output)\n        \n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits, labels)\n        return {\"loss\": loss, \"logits\": logits}\n\nmodel = FrozenBertForGrammarScoring.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# Verify freezing\nprint(\"BERT frozen except last 2 layers and pooler:\")\nfor name, param in model.named_parameters():\n    print(f\"{name}: {'Trainable' if param.requires_grad else 'Frozen'}\")\n\n# =============================================\n# 4. Training Setup with Pearson Optimization\n# =============================================\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    \n    # Convert class indices back to original scores (01.0, 11.5, etc.)\n    pred_scores = 1.0 + (predictions * 0.5)\n    true_scores = 1.0 + (labels * 0.5)\n    \n    return {\n        \"accuracy\": accuracy_score(labels, predictions),\n        \"pearson\": pearsonr(pred_scores, true_scores)[0],\n        \"mse\": mean_squared_error(true_scores, pred_scores)\n    }\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=64,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"pearson\",\n    greater_is_better=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=train_dataset,  # Use validation split if available\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 5. Train the Model\n# =============================================\ntrainer.train()\n\n# =============================================\n# 6. Generate Predictions\n# =============================================\ntest_predictions = trainer.predict(test_dataset)\npredicted_classes = np.argmax(test_predictions.predictions, axis=1)\npredicted_scores = 1.0 + (predicted_classes * 0.5)  # Convert to 1.0-5.0 scale\n\n# Create submission\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n# submission.to_csv(\"submission.csv\", index=False)\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n# print(\"Training complete! Submission saved to submission.csv\")\nif os.path.exists(submission_path):\n    print(f\"Submission successfully saved to: {submission_path}\")\n    print(\"File preview:\")\n    print(pd.read_csv(submission_path).head())\nelse:\n    print(\"Error: File not saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T21:28:15.178384Z","iopub.execute_input":"2025-04-06T21:28:15.178690Z","iopub.status.idle":"2025-04-06T21:31:57.006941Z","shell.execute_reply.started":"2025-04-06T21:28:15.178667Z","shell.execute_reply":"2025-04-06T21:31:57.005613Z"}},"outputs":[{"name":"stdout","text":"Sample training texts: [' My favorite hobby is cultivation of plants such as gardening offers a rewarding experience with gardening. I can gain immense of plants to plant and the flowers and herbs to vegetables.', ' The playground looks like very clear and neat as there are lot of colorful things like a basketball court for playing or we can do gym swing on swings group of friends together play very well and they love each other']\nSample labels: tensor([0, 1])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e1d48c9cd954c7fb4be3332991bc858"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a59282536a4149824b0629c100bbca"}},"metadata":{}},{"name":"stderr","text":"Some weights of FrozenBertForGrammarScoring were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.0.bias', 'classifier.0.weight', 'classifier.3.bias', 'classifier.3.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"BERT frozen except last 2 layers and pooler:\nbert.embeddings.word_embeddings.weight: Frozen\nbert.embeddings.position_embeddings.weight: Frozen\nbert.embeddings.token_type_embeddings.weight: Frozen\nbert.embeddings.LayerNorm.weight: Frozen\nbert.embeddings.LayerNorm.bias: Frozen\nbert.encoder.layer.0.attention.self.query.weight: Frozen\nbert.encoder.layer.0.attention.self.query.bias: Frozen\nbert.encoder.layer.0.attention.self.key.weight: Frozen\nbert.encoder.layer.0.attention.self.key.bias: Frozen\nbert.encoder.layer.0.attention.self.value.weight: Frozen\nbert.encoder.layer.0.attention.self.value.bias: Frozen\nbert.encoder.layer.0.attention.output.dense.weight: Frozen\nbert.encoder.layer.0.attention.output.dense.bias: Frozen\nbert.encoder.layer.0.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.0.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.0.intermediate.dense.weight: Frozen\nbert.encoder.layer.0.intermediate.dense.bias: Frozen\nbert.encoder.layer.0.output.dense.weight: Frozen\nbert.encoder.layer.0.output.dense.bias: Frozen\nbert.encoder.layer.0.output.LayerNorm.weight: Frozen\nbert.encoder.layer.0.output.LayerNorm.bias: Frozen\nbert.encoder.layer.1.attention.self.query.weight: Frozen\nbert.encoder.layer.1.attention.self.query.bias: Frozen\nbert.encoder.layer.1.attention.self.key.weight: Frozen\nbert.encoder.layer.1.attention.self.key.bias: Frozen\nbert.encoder.layer.1.attention.self.value.weight: Frozen\nbert.encoder.layer.1.attention.self.value.bias: Frozen\nbert.encoder.layer.1.attention.output.dense.weight: Frozen\nbert.encoder.layer.1.attention.output.dense.bias: Frozen\nbert.encoder.layer.1.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.1.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.1.intermediate.dense.weight: Frozen\nbert.encoder.layer.1.intermediate.dense.bias: Frozen\nbert.encoder.layer.1.output.dense.weight: Frozen\nbert.encoder.layer.1.output.dense.bias: Frozen\nbert.encoder.layer.1.output.LayerNorm.weight: Frozen\nbert.encoder.layer.1.output.LayerNorm.bias: Frozen\nbert.encoder.layer.2.attention.self.query.weight: Frozen\nbert.encoder.layer.2.attention.self.query.bias: Frozen\nbert.encoder.layer.2.attention.self.key.weight: Frozen\nbert.encoder.layer.2.attention.self.key.bias: Frozen\nbert.encoder.layer.2.attention.self.value.weight: Frozen\nbert.encoder.layer.2.attention.self.value.bias: Frozen\nbert.encoder.layer.2.attention.output.dense.weight: Frozen\nbert.encoder.layer.2.attention.output.dense.bias: Frozen\nbert.encoder.layer.2.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.2.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.2.intermediate.dense.weight: Frozen\nbert.encoder.layer.2.intermediate.dense.bias: Frozen\nbert.encoder.layer.2.output.dense.weight: Frozen\nbert.encoder.layer.2.output.dense.bias: Frozen\nbert.encoder.layer.2.output.LayerNorm.weight: Frozen\nbert.encoder.layer.2.output.LayerNorm.bias: Frozen\nbert.encoder.layer.3.attention.self.query.weight: Frozen\nbert.encoder.layer.3.attention.self.query.bias: Frozen\nbert.encoder.layer.3.attention.self.key.weight: Frozen\nbert.encoder.layer.3.attention.self.key.bias: Frozen\nbert.encoder.layer.3.attention.self.value.weight: Frozen\nbert.encoder.layer.3.attention.self.value.bias: Frozen\nbert.encoder.layer.3.attention.output.dense.weight: Frozen\nbert.encoder.layer.3.attention.output.dense.bias: Frozen\nbert.encoder.layer.3.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.3.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.3.intermediate.dense.weight: Frozen\nbert.encoder.layer.3.intermediate.dense.bias: Frozen\nbert.encoder.layer.3.output.dense.weight: Frozen\nbert.encoder.layer.3.output.dense.bias: Frozen\nbert.encoder.layer.3.output.LayerNorm.weight: Frozen\nbert.encoder.layer.3.output.LayerNorm.bias: Frozen\nbert.encoder.layer.4.attention.self.query.weight: Frozen\nbert.encoder.layer.4.attention.self.query.bias: Frozen\nbert.encoder.layer.4.attention.self.key.weight: Frozen\nbert.encoder.layer.4.attention.self.key.bias: Frozen\nbert.encoder.layer.4.attention.self.value.weight: Frozen\nbert.encoder.layer.4.attention.self.value.bias: Frozen\nbert.encoder.layer.4.attention.output.dense.weight: Frozen\nbert.encoder.layer.4.attention.output.dense.bias: Frozen\nbert.encoder.layer.4.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.4.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.4.intermediate.dense.weight: Frozen\nbert.encoder.layer.4.intermediate.dense.bias: Frozen\nbert.encoder.layer.4.output.dense.weight: Frozen\nbert.encoder.layer.4.output.dense.bias: Frozen\nbert.encoder.layer.4.output.LayerNorm.weight: Frozen\nbert.encoder.layer.4.output.LayerNorm.bias: Frozen\nbert.encoder.layer.5.attention.self.query.weight: Frozen\nbert.encoder.layer.5.attention.self.query.bias: Frozen\nbert.encoder.layer.5.attention.self.key.weight: Frozen\nbert.encoder.layer.5.attention.self.key.bias: Frozen\nbert.encoder.layer.5.attention.self.value.weight: Frozen\nbert.encoder.layer.5.attention.self.value.bias: Frozen\nbert.encoder.layer.5.attention.output.dense.weight: Frozen\nbert.encoder.layer.5.attention.output.dense.bias: Frozen\nbert.encoder.layer.5.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.5.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.5.intermediate.dense.weight: Frozen\nbert.encoder.layer.5.intermediate.dense.bias: Frozen\nbert.encoder.layer.5.output.dense.weight: Frozen\nbert.encoder.layer.5.output.dense.bias: Frozen\nbert.encoder.layer.5.output.LayerNorm.weight: Frozen\nbert.encoder.layer.5.output.LayerNorm.bias: Frozen\nbert.encoder.layer.6.attention.self.query.weight: Frozen\nbert.encoder.layer.6.attention.self.query.bias: Frozen\nbert.encoder.layer.6.attention.self.key.weight: Frozen\nbert.encoder.layer.6.attention.self.key.bias: Frozen\nbert.encoder.layer.6.attention.self.value.weight: Frozen\nbert.encoder.layer.6.attention.self.value.bias: Frozen\nbert.encoder.layer.6.attention.output.dense.weight: Frozen\nbert.encoder.layer.6.attention.output.dense.bias: Frozen\nbert.encoder.layer.6.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.6.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.6.intermediate.dense.weight: Frozen\nbert.encoder.layer.6.intermediate.dense.bias: Frozen\nbert.encoder.layer.6.output.dense.weight: Frozen\nbert.encoder.layer.6.output.dense.bias: Frozen\nbert.encoder.layer.6.output.LayerNorm.weight: Frozen\nbert.encoder.layer.6.output.LayerNorm.bias: Frozen\nbert.encoder.layer.7.attention.self.query.weight: Frozen\nbert.encoder.layer.7.attention.self.query.bias: Frozen\nbert.encoder.layer.7.attention.self.key.weight: Frozen\nbert.encoder.layer.7.attention.self.key.bias: Frozen\nbert.encoder.layer.7.attention.self.value.weight: Frozen\nbert.encoder.layer.7.attention.self.value.bias: Frozen\nbert.encoder.layer.7.attention.output.dense.weight: Frozen\nbert.encoder.layer.7.attention.output.dense.bias: Frozen\nbert.encoder.layer.7.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.7.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.7.intermediate.dense.weight: Frozen\nbert.encoder.layer.7.intermediate.dense.bias: Frozen\nbert.encoder.layer.7.output.dense.weight: Frozen\nbert.encoder.layer.7.output.dense.bias: Frozen\nbert.encoder.layer.7.output.LayerNorm.weight: Frozen\nbert.encoder.layer.7.output.LayerNorm.bias: Frozen\nbert.encoder.layer.8.attention.self.query.weight: Frozen\nbert.encoder.layer.8.attention.self.query.bias: Frozen\nbert.encoder.layer.8.attention.self.key.weight: Frozen\nbert.encoder.layer.8.attention.self.key.bias: Frozen\nbert.encoder.layer.8.attention.self.value.weight: Frozen\nbert.encoder.layer.8.attention.self.value.bias: Frozen\nbert.encoder.layer.8.attention.output.dense.weight: Frozen\nbert.encoder.layer.8.attention.output.dense.bias: Frozen\nbert.encoder.layer.8.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.8.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.8.intermediate.dense.weight: Frozen\nbert.encoder.layer.8.intermediate.dense.bias: Frozen\nbert.encoder.layer.8.output.dense.weight: Frozen\nbert.encoder.layer.8.output.dense.bias: Frozen\nbert.encoder.layer.8.output.LayerNorm.weight: Frozen\nbert.encoder.layer.8.output.LayerNorm.bias: Frozen\nbert.encoder.layer.9.attention.self.query.weight: Frozen\nbert.encoder.layer.9.attention.self.query.bias: Frozen\nbert.encoder.layer.9.attention.self.key.weight: Frozen\nbert.encoder.layer.9.attention.self.key.bias: Frozen\nbert.encoder.layer.9.attention.self.value.weight: Frozen\nbert.encoder.layer.9.attention.self.value.bias: Frozen\nbert.encoder.layer.9.attention.output.dense.weight: Frozen\nbert.encoder.layer.9.attention.output.dense.bias: Frozen\nbert.encoder.layer.9.attention.output.LayerNorm.weight: Frozen\nbert.encoder.layer.9.attention.output.LayerNorm.bias: Frozen\nbert.encoder.layer.9.intermediate.dense.weight: Frozen\nbert.encoder.layer.9.intermediate.dense.bias: Frozen\nbert.encoder.layer.9.output.dense.weight: Frozen\nbert.encoder.layer.9.output.dense.bias: Frozen\nbert.encoder.layer.9.output.LayerNorm.weight: Frozen\nbert.encoder.layer.9.output.LayerNorm.bias: Frozen\nbert.encoder.layer.10.attention.self.query.weight: Trainable\nbert.encoder.layer.10.attention.self.query.bias: Trainable\nbert.encoder.layer.10.attention.self.key.weight: Trainable\nbert.encoder.layer.10.attention.self.key.bias: Trainable\nbert.encoder.layer.10.attention.self.value.weight: Trainable\nbert.encoder.layer.10.attention.self.value.bias: Trainable\nbert.encoder.layer.10.attention.output.dense.weight: Trainable\nbert.encoder.layer.10.attention.output.dense.bias: Trainable\nbert.encoder.layer.10.attention.output.LayerNorm.weight: Trainable\nbert.encoder.layer.10.attention.output.LayerNorm.bias: Trainable\nbert.encoder.layer.10.intermediate.dense.weight: Trainable\nbert.encoder.layer.10.intermediate.dense.bias: Trainable\nbert.encoder.layer.10.output.dense.weight: Trainable\nbert.encoder.layer.10.output.dense.bias: Trainable\nbert.encoder.layer.10.output.LayerNorm.weight: Trainable\nbert.encoder.layer.10.output.LayerNorm.bias: Trainable\nbert.encoder.layer.11.attention.self.query.weight: Trainable\nbert.encoder.layer.11.attention.self.query.bias: Trainable\nbert.encoder.layer.11.attention.self.key.weight: Trainable\nbert.encoder.layer.11.attention.self.key.bias: Trainable\nbert.encoder.layer.11.attention.self.value.weight: Trainable\nbert.encoder.layer.11.attention.self.value.bias: Trainable\nbert.encoder.layer.11.attention.output.dense.weight: Trainable\nbert.encoder.layer.11.attention.output.dense.bias: Trainable\nbert.encoder.layer.11.attention.output.LayerNorm.weight: Trainable\nbert.encoder.layer.11.attention.output.LayerNorm.bias: Trainable\nbert.encoder.layer.11.intermediate.dense.weight: Trainable\nbert.encoder.layer.11.intermediate.dense.bias: Trainable\nbert.encoder.layer.11.output.dense.weight: Trainable\nbert.encoder.layer.11.output.dense.bias: Trainable\nbert.encoder.layer.11.output.LayerNorm.weight: Trainable\nbert.encoder.layer.11.output.LayerNorm.bias: Trainable\nbert.pooler.dense.weight: Trainable\nbert.pooler.dense.bias: Trainable\nclassifier.0.weight: Trainable\nclassifier.0.bias: Trainable\nclassifier.3.weight: Trainable\nclassifier.3.bias: Trainable\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='267' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [267/448 03:24 < 02:19, 1.30 it/s, Epoch 38/64]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Pearson</th>\n      <th>Mse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.096143</td>\n      <td>0.247748</td>\n      <td>nan</td>\n      <td>3.150901</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>2.013901</td>\n      <td>0.247748</td>\n      <td>nan</td>\n      <td>3.150901</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.938979</td>\n      <td>0.310811</td>\n      <td>0.440079</td>\n      <td>2.225225</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.865320</td>\n      <td>0.351351</td>\n      <td>0.596855</td>\n      <td>1.556306</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.794715</td>\n      <td>0.376126</td>\n      <td>0.662243</td>\n      <td>1.268018</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.733720</td>\n      <td>0.385135</td>\n      <td>0.697103</td>\n      <td>1.099099</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.662381</td>\n      <td>0.414414</td>\n      <td>0.765483</td>\n      <td>0.828829</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.604514</td>\n      <td>0.423423</td>\n      <td>0.785393</td>\n      <td>0.740991</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.567567</td>\n      <td>0.427928</td>\n      <td>0.798590</td>\n      <td>0.691441</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>1.489531</td>\n      <td>0.463964</td>\n      <td>0.833994</td>\n      <td>0.581081</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>1.439018</td>\n      <td>0.466216</td>\n      <td>0.850550</td>\n      <td>0.531532</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>No log</td>\n      <td>1.392459</td>\n      <td>0.488739</td>\n      <td>0.867700</td>\n      <td>0.465653</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>No log</td>\n      <td>1.377188</td>\n      <td>0.481982</td>\n      <td>0.861191</td>\n      <td>0.474662</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>No log</td>\n      <td>1.293211</td>\n      <td>0.515766</td>\n      <td>0.894232</td>\n      <td>0.368806</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>No log</td>\n      <td>1.251827</td>\n      <td>0.524775</td>\n      <td>0.892783</td>\n      <td>0.359797</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>No log</td>\n      <td>1.209439</td>\n      <td>0.547297</td>\n      <td>0.899285</td>\n      <td>0.323198</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>No log</td>\n      <td>1.171350</td>\n      <td>0.569820</td>\n      <td>0.907579</td>\n      <td>0.301239</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>No log</td>\n      <td>1.119917</td>\n      <td>0.603604</td>\n      <td>0.913795</td>\n      <td>0.275901</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>No log</td>\n      <td>1.068652</td>\n      <td>0.655405</td>\n      <td>0.919984</td>\n      <td>0.240991</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>No log</td>\n      <td>1.026087</td>\n      <td>0.677928</td>\n      <td>0.924801</td>\n      <td>0.227477</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>No log</td>\n      <td>0.972998</td>\n      <td>0.707207</td>\n      <td>0.934313</td>\n      <td>0.189189</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>No log</td>\n      <td>0.929666</td>\n      <td>0.720721</td>\n      <td>0.934732</td>\n      <td>0.193694</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>No log</td>\n      <td>0.884135</td>\n      <td>0.750000</td>\n      <td>0.943610</td>\n      <td>0.154842</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>No log</td>\n      <td>0.834125</td>\n      <td>0.795045</td>\n      <td>0.951676</td>\n      <td>0.128941</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>No log</td>\n      <td>0.771548</td>\n      <td>0.846847</td>\n      <td>0.955351</td>\n      <td>0.115991</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>No log</td>\n      <td>0.741870</td>\n      <td>0.846847</td>\n      <td>0.962803</td>\n      <td>0.094595</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>No log</td>\n      <td>0.697183</td>\n      <td>0.867117</td>\n      <td>0.966454</td>\n      <td>0.086149</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>No log</td>\n      <td>0.662296</td>\n      <td>0.876126</td>\n      <td>0.968735</td>\n      <td>0.080518</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>No log</td>\n      <td>0.608042</td>\n      <td>0.909910</td>\n      <td>0.975897</td>\n      <td>0.060248</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>No log</td>\n      <td>0.584587</td>\n      <td>0.907658</td>\n      <td>0.975957</td>\n      <td>0.060811</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>No log</td>\n      <td>0.538594</td>\n      <td>0.921171</td>\n      <td>0.976052</td>\n      <td>0.059122</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>No log</td>\n      <td>0.525321</td>\n      <td>0.916667</td>\n      <td>0.975618</td>\n      <td>0.061374</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>No log</td>\n      <td>0.503169</td>\n      <td>0.927928</td>\n      <td>0.978383</td>\n      <td>0.054054</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>No log</td>\n      <td>0.453012</td>\n      <td>0.954955</td>\n      <td>0.981468</td>\n      <td>0.045608</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>No log</td>\n      <td>0.460556</td>\n      <td>0.916667</td>\n      <td>0.971798</td>\n      <td>0.070946</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>No log</td>\n      <td>0.417622</td>\n      <td>0.945946</td>\n      <td>0.975000</td>\n      <td>0.061937</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>No log</td>\n      <td>0.385778</td>\n      <td>0.959459</td>\n      <td>0.981820</td>\n      <td>0.045045</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>No log</td>\n      <td>0.395081</td>\n      <td>0.948198</td>\n      <td>0.975279</td>\n      <td>0.061374</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"<ipython-input-18-189c1a281713>:90: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  \"pearson\": pearsonr(pred_scores, true_scores)[0],\n/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3161: RuntimeWarning: invalid value encountered in greater\n  if operator(metric_value, self.state.best_metric):\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n<ipython-input-18-189c1a281713>:90: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  \"pearson\": pearsonr(pred_scores, true_scores)[0],\n/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3161: RuntimeWarning: invalid value encountered in greater\n  if operator(metric_value, self.state.best_metric):\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-189c1a281713>\u001b[0m in \u001b[0;36m<cell line: 119>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# 5. Train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# =============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# =============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3055\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3184\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3185\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3806\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3908\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3909\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3910\u001b[0;31m             self.model.save_pretrained(\n\u001b[0m\u001b[1;32m   3911\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3912\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m                 \u001b[0;31m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3033\u001b[0m                 \u001b[0;31m# joyfulness), but for now this enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3034\u001b[0;31m                 \u001b[0msafe_save_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3035\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m                 \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mserialize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })"],"ename":"SafetensorError","evalue":"Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"import os\n\n# Delete a file\nos.remove(\"/kaggle/working/train_transcribed.csv\")  # replace with your filename\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T22:28:34.443542Z","iopub.execute_input":"2025-04-06T22:28:34.443932Z","iopub.status.idle":"2025-04-06T22:28:34.448044Z","shell.execute_reply.started":"2025-04-06T22:28:34.443902Z","shell.execute_reply":"2025-04-06T22:28:34.447159Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import shutil\n\ntry:\n    # shutil.rmtree('/kaggle/working/results')\n    shutil.rmtree('/kaggle/working/enhanced_results')\n    \n    print(\"Successfully removed /kaggle/working/results\")\nexcept FileNotFoundError:\n    print(\"Folder doesn't exist\")\nexcept Exception as e:\n    print(f\"Error removing folder: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T23:59:35.250046Z","iopub.execute_input":"2025-04-06T23:59:35.250398Z","iopub.status.idle":"2025-04-06T23:59:35.255716Z","shell.execute_reply.started":"2025-04-06T23:59:35.250367Z","shell.execute_reply":"2025-04-06T23:59:35.254883Z"}},"outputs":[{"name":"stdout","text":"Successfully removed /kaggle/working/results\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import BertTokenizer, TrainingArguments, Trainer\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics import mean_squared_error\nimport os\n\n# =============================================\n# 1. Use Your Existing Class-Based Labels\n# =============================================\n# Your labels are already converted to classes 0-8 (1.0-5.0 in 0.5 steps)\nprint(\"Label samples:\", train_dataset[\"label\"][:5])\n\n# =============================================\n# 2. Tokenization (Keep Your Existing Code)\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_dataset = train_dataset.map(tokenize, batched=True)\ntest_dataset = test_dataset.map(tokenize, batched=True)\n\n# Set format for PyTorch\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. Modified Model for Continuous Output\n# =============================================\nfrom transformers import BertPreTrainedModel, BertModel\nimport torch.nn as nn\n\nclass BertForContinuousScoring(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n        \n        # Freeze all BERT layers except last 2\n        for param in self.bert.parameters():\n            param.requires_grad = False\n        for layer in self.bert.encoder.layer[-2:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n                \n        # Modified head - outputs continuous values\n        self.scoring_head = nn.Sequential(\n            nn.Linear(config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1),\n            nn.Sigmoid()  # Constrains output to 0-1\n        )\n        self.scale = 5.0  # Scale to 0-5 range\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        raw_score = self.scoring_head(pooled_output)\n        score = raw_score * self.scale  # Convert to 0-5 range\n        \n        loss = None\n        if labels is not None:\n            # Convert class labels back to original 1.0-5.0 scale for regression\n            true_scores = 1.0 + (labels.float() * 0.5)\n            loss_fct = nn.MSELoss()\n            loss = loss_fct(score.squeeze(), true_scores)\n        return {\"loss\": loss, \"score\": score}\n\nmodel = BertForContinuousScoring.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 4. Training Setup with Pearson Optimization\n# =============================================\ndef compute_metrics(eval_pred):\n    scores, labels = eval_pred\n    scores = scores.squeeze()\n    # Convert class indices back to original 1.0-5.0 scale\n    true_scores = 1.0 + (labels * 0.5)\n    return {\n        \"pearson\": pearsonr(scores, true_scores)[0],\n        \"mse\": mean_squared_error(true_scores, scores)\n    }\n\ntraining_args = TrainingArguments(\n    output_dir=\"/tmp\",  # Temporary, gets discarded\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=64,\n    evaluation_strategy=\"no\",  # No evaluation during training\n    save_strategy=\"no\",        # Prevent saving checkpoints\n    logging_strategy=\"no\",     # Skip logging if you want it cleaner\n    report_to=\"none\",\n    fp16=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=train_dataset,  # Use validation split if available\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 5. Train the Model\n# =============================================\ntrainer.train()\n\n# =============================================\n# 6. Generate Continuous Predictions (0-5)\n# =============================================\ntest_predictions = trainer.predict(test_dataset)\npredicted_scores = test_predictions.predictions.squeeze()\n\n# Clip to ensure 0-5 range and round to 2 decimals\npredicted_scores = np.clip(predicted_scores, 0.0, 5.0)\npredicted_scores = np.round(predicted_scores, 2)\n\n# Create submission\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n\nprint(f\"Continuous predictions saved to {submission_path}\")\nprint(\"Sample predictions:\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T21:49:46.315213Z","iopub.execute_input":"2025-04-06T21:49:46.315606Z","iopub.status.idle":"2025-04-06T21:52:58.608367Z","shell.execute_reply.started":"2025-04-06T21:49:46.315576Z","shell.execute_reply":"2025-04-06T21:52:58.606866Z"}},"outputs":[{"name":"stdout","text":"Label samples: tensor([0, 1, 1, 1, 2])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a5615ac2a940e1a726068a475f9ae5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524c1090d943416ba1732f93ae776ffb"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForContinuousScoring were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['scoring_head.0.bias', 'scoring_head.0.weight', 'scoring_head.3.bias', 'scoring_head.3.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='448' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [448/448 02:58, Epoch 64/64]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-5f93e79a30dd>\u001b[0m in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# 6. Generate Continuous Predictions (0-5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# =============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0mpredicted_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4128\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4129\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4130\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4131\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4265\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4267\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4268\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2600\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2601\u001b[0m         \"\"\"\n\u001b[0;32m-> 2602\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_fp32_wrapper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedOperationException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{function.__module__}.{function.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m     return recursively_apply(\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         return honor_type(\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             (\n\u001b[0;32m--> 111\u001b[0;31m                 recursively_apply(\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_on_other_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;34mf\"Unsupported types ({type(data)}) passed to `{func.__name__}`. Only nested list/tuple/dicts of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;34mf\"objects that are valid for `{test_type.__name__}` should be passed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Unsupported types (<class 'NoneType'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed."],"ename":"TypeError","evalue":"Unsupported types (<class 'NoneType'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed.","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import BertTokenizer, TrainingArguments, Trainer\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics import mean_squared_error\nimport os\n\n# =============================================\n# 1. Convert Class Labels Back to 0-5 Scores\n# =============================================\ntrain_df[\"label\"] = 1.0 + (train_df[\"label\"] * 0.5)  # Convert 01.0, 11.5, ..., 85.0\ntrain_dataset = Dataset.from_pandas(train_df)\n\n# =============================================\n# 2. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_dataset = train_dataset.map(tokenize, batched=True)\ntest_dataset = test_dataset.map(tokenize, batched=True)\n\n# Set format for PyTorch\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. Regression Model\n# =============================================\nfrom transformers import BertPreTrainedModel, BertModel\nimport torch.nn as nn\n\nclass BertForRegression(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n        self.regressor = nn.Sequential(\n            nn.Linear(config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n        self.scale = 5.0\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        score = self.regressor(pooled_output) * self.scale\n        loss = None\n        if labels is not None:\n            loss_fct = nn.MSELoss()\n            loss = loss_fct(score.squeeze(), labels)\n        return {\"loss\": loss, \"score\": score}\n\nmodel = BertForRegression.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 4. Training Setup (No Checkpoint Saving)\n# =============================================\ntraining_args = TrainingArguments(\n    output_dir=\"./tmp\",  # Temporary directory\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=30,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",  # Disable checkpoint saving\n    logging_dir=\"./logs\",\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    compute_metrics=lambda eval_pred: {\n        \"pearson\": pearsonr(eval_pred.predictions.squeeze(), eval_pred.label_ids)[0],\n        \"mse\": mean_squared_error(eval_pred.label_ids, eval_pred.predictions.squeeze())\n    },\n)\n\n# =============================================\n# 5. Train and Save Only Final CSV\n# =============================================\n# Train without saving checkpoints\ntrainer.train()\n\n# Generate predictions\ntest_predictions = trainer.predict(test_dataset)\npredicted_scores = np.clip(test_predictions.predictions.squeeze(), 0.0, 5.0).round(2)\n\n# Create clean submission\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n\n# Save final CSV\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n\n\nprint(f\"Final submission saved to {submission_path}\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T21:58:17.326724Z","iopub.execute_input":"2025-04-06T21:58:17.327055Z","iopub.status.idle":"2025-04-06T21:58:17.854164Z","shell.execute_reply.started":"2025-04-06T21:58:17.327033Z","shell.execute_reply":"2025-04-06T21:58:17.853081Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c03e96f915dc47f7b20e8a81c3a4a4ae"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-cfb1fec7c2be>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m         }\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3077\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3079\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3080\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3509\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                     \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m                         \u001b[0mnum_examples_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36miter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3459\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshard_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3461\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m         \u001b[0mnum_examples_progress_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3388\u001b[0m             \u001b[0;34m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3390\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3391\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprepare_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-cfb1fec7c2be>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys_to_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'text'"],"ename":"KeyError","evalue":"'text'","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"print(train_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T22:15:09.550482Z","iopub.execute_input":"2025-04-06T22:15:09.550811Z","iopub.status.idle":"2025-04-06T22:15:09.556242Z","shell.execute_reply.started":"2025-04-06T22:15:09.550786Z","shell.execute_reply":"2025-04-06T22:15:09.555151Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['filename', 'label', 'audio_path'],\n    num_rows: 444\n})\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import BertTokenizer, TrainingArguments, Trainer\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics import mean_squared_error\n\n# =============================================\n# 1. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_dataset = train_dataset.map(tokenize, batched=True)\ntest_dataset = test_dataset.map(tokenize, batched=True)\n\n# Make sure label is float (for regression)\ntrain_dataset = train_dataset.cast_column(\"label\", \"float\")\n\n# Set format for PyTorch\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 2. Regression Model\n# =============================================\nfrom transformers import BertPreTrainedModel, BertModel\nimport torch.nn as nn\n\nclass BertRegressionModel(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n\n        for param in self.bert.parameters():\n            param.requires_grad = False\n        for layer in self.bert.encoder.layer[-2:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        for param in self.bert.pooler.parameters():\n            param.requires_grad = True\n\n        self.regressor = nn.Sequential(\n            nn.Linear(config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1)  # Regression output\n        )\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        scores = self.regressor(pooled_output).squeeze(-1)\n\n        loss = None\n        if labels is not None:\n            loss_fct = nn.MSELoss()\n            loss = loss_fct(scores, labels)\n        return {\"loss\": loss, \"logits\": scores}\n\nmodel = BertRegressionModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 3. Metrics\n# =============================================\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.clip(predictions.flatten(), 1.0, 5.0)\n    labels = labels.flatten()\n    return {\n        \"pearson\": pearsonr(predictions, labels)[0],\n        \"mse\": mean_squared_error(labels, predictions)\n    }\n\n# =============================================\n# 4. TrainingArguments (temp dir, no save)\n# =============================================\ntraining_args = TrainingArguments(\n    output_dir=\"/tmp\",  # dummy path; won't use it\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=64,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",  # <- disables saving\n    logging_strategy=\"epoch\",\n    load_best_model_at_end=False,\n    report_to=\"none\",\n    fp16=True,\n)\n\n# =============================================\n# 5. Trainer\n# =============================================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=train_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 6. Train\n# =============================================\ntrainer.train()\n\n# =============================================\n# 7. Predict\n# =============================================\ntest_predictions = trainer.predict(test_dataset)\npredicted_scores = np.clip(test_predictions.predictions.flatten(), 1.0, 5.0)\n\n# Create submission\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\nprint(\"Sample predictions:\")\nprint(submission.head())\nimport os\nimport pandas as pd\n\n# Define path to save CSV\nsubmission_path = \"/kaggle/working/submission.csv\"\n\n# Create submission DataFrame\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n\n# Save to CSV\nsubmission.to_csv(submission_path, index=False)\n\n# Confirm it's saved\nif os.path.exists(submission_path):\n    print(f\" Submission saved to: {submission_path}\")\n    print(submission.head())\nelse:\n    print(\" Error: File not saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T22:13:21.520022Z","iopub.execute_input":"2025-04-06T22:13:21.520372Z","iopub.status.idle":"2025-04-06T22:13:22.286100Z","shell.execute_reply.started":"2025-04-06T22:13:21.520348Z","shell.execute_reply":"2025-04-06T22:13:22.284969Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23e27c92ef6f453ba3e4eed517b0bd29"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-1fbe5df4aa75>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m         }\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3077\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3079\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3080\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3509\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                     \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m                         \u001b[0mnum_examples_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36miter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3459\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshard_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3461\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m         \u001b[0mnum_examples_progress_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3388\u001b[0m             \u001b[0;34m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3390\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3391\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprepare_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-1fbe5df4aa75>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys_to_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'text'"],"ename":"KeyError","evalue":"'text'","output_type":"error"}],"execution_count":26},{"cell_type":"markdown","source":"### Approach -1 (submitted) (documentation needed)(so submit again)","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import BertTokenizer, TrainingArguments, Trainer, BertPreTrainedModel, BertModel\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport torch.nn as nn\n\n\n\n# Convert to HuggingFace datasets\nhf_train_dataset = Dataset.from_pandas(train_df_with_text)\nhf_test_dataset = Dataset.from_pandas(test_df_with_text)\n\n# =============================================\n# 2. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nhf_train_dataset = hf_train_dataset.map(tokenize, batched=True)\nhf_test_dataset = hf_test_dataset.map(tokenize, batched=True)\n\nhf_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nhf_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. BERT Model for Regression (Frozen Base)\n# =============================================\nclass BertRegressionModel(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n\n        # Freeze all layers\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n        # Unfreeze last 2 encoder layers + pooler\n        for layer in self.bert.encoder.layer[-2:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        for param in self.bert.pooler.parameters():\n            param.requires_grad = True\n\n        self.regressor = nn.Sequential(\n            nn.Linear(config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        logits = self.regressor(pooled_output).squeeze(-1)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.MSELoss()\n            loss = loss_fn(logits, labels.float())\n\n        return {\"loss\": loss, \"logits\": logits}\n\nmodel = BertRegressionModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 4. Metrics (Regression + Accuracy)\n# =============================================\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.flatten()\n    labels = labels.flatten()\n    predictions = np.clip(predictions, 0, 5)\n\n    # Accuracy after rounding to nearest 0.5\n    pred_rounded = np.round(predictions * 2) / 2\n    label_rounded = np.round(labels * 2) / 2\n    accuracy = np.mean(pred_rounded == label_rounded)\n\n    return {\n        \"mse\": mean_squared_error(labels, predictions),\n        \"pearson\": pearsonr(predictions, labels)[0],\n        \"accuracy\": accuracy\n    }\n\n# =============================================\n# 5. Training Arguments\n# =============================================\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=64,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    # load_best_model_at_end=True,\n    # metric_for_best_model=\"pearson\",\n    # greater_is_better=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\n# =============================================\n# 6. Trainer Setup\n# =============================================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=hf_train_dataset,\n    eval_dataset=hf_train_dataset,  # Use validation set if available\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 7. Train the Model\n# =============================================\ntrainer.train()\n\n# # =============================================\n# # 8. Inference on Test Set\n# # =============================================\n# predictions = trainer.predict(hf_test_dataset)\n# predicted_scores = np.clip(predictions.predictions.flatten(), 0, 5)\n\n# # =============================================\n# # 9. Submission File\n# # =============================================\n# submission = pd.DataFrame({\n#     \"filename\": test_df[\"filename\"],\n#     \"label\": predicted_scores\n# })\n\n# submission_path = \"/kaggle/working/submission.csv\"\n# submission.to_csv(submission_path, index=False)\n\n# if os.path.exists(submission_path):\n#     print(f\" Submission saved to: {submission_path}\")\n#     print(submission.head())\n# else:\n#     print(\" Error: Submission file not saved!\")\n\n# =============================================\n# 8. Inference on Test Set (Corrected)\n# =============================================\n\n# 1. First, make sure the test dataset has the right format (only input features)\nhf_test_dataset.set_format(\n    type=\"torch\", \n    columns=[\"input_ids\", \"attention_mask\"]  # No labels needed\n)\n\n# 2. Create a custom prediction function\ndef predict_without_labels(model, dataset):\n    model.eval()\n    predictions = []\n    \n    # Create dataloader\n    dataloader = torch.utils.data.DataLoader(\n        dataset, \n        batch_size=training_args.per_device_eval_batch_size\n    )\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            # Move batch to GPU\n            inputs = {\n                'input_ids': batch['input_ids'].to('cuda'),\n                'attention_mask': batch['attention_mask'].to('cuda')\n            }\n            \n            # Forward pass\n            outputs = model(**inputs)\n            predictions.append(outputs['logits'].cpu().numpy())\n    \n    return np.concatenate(predictions, axis=0)\n\n# 3. Run prediction\npredicted_scores = predict_without_labels(model, hf_test_dataset)\npredicted_scores = np.clip(predicted_scores.flatten(), 0, 5)\n# =============================================\n# 9. Submission File\n# =============================================\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n\nif os.path.exists(submission_path):\n    print(f\" Submission saved to: {submission_path}\")\n    print(submission.head())\nelse:\n    print(\" Error: Submission file not saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T23:20:32.685063Z","iopub.execute_input":"2025-04-06T23:20:32.685441Z","iopub.status.idle":"2025-04-06T23:25:51.116161Z","shell.execute_reply.started":"2025-04-06T23:20:32.685413Z","shell.execute_reply":"2025-04-06T23:25:51.115315Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce9aae1a7d484379a7707486a1973b01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea97498ea30149f198713834c60a6df6"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertRegressionModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['regressor.0.bias', 'regressor.0.weight', 'regressor.3.bias', 'regressor.3.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='448' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [448/448 04:59, Epoch 64/64]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mse</th>\n      <th>Pearson</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>9.901956</td>\n      <td>9.901956</td>\n      <td>0.065033</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>7.058571</td>\n      <td>7.058571</td>\n      <td>0.099318</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>4.998337</td>\n      <td>4.998336</td>\n      <td>0.080044</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>3.436476</td>\n      <td>3.436476</td>\n      <td>0.077346</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>2.316699</td>\n      <td>2.316698</td>\n      <td>0.076595</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.603327</td>\n      <td>1.603326</td>\n      <td>0.090771</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.264351</td>\n      <td>1.264351</td>\n      <td>0.132564</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.199672</td>\n      <td>1.199672</td>\n      <td>0.566352</td>\n      <td>0.137387</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.922330</td>\n      <td>0.922330</td>\n      <td>0.652656</td>\n      <td>0.135135</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>0.680618</td>\n      <td>0.680618</td>\n      <td>0.688186</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>0.665957</td>\n      <td>0.665957</td>\n      <td>0.693776</td>\n      <td>0.198198</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>No log</td>\n      <td>0.499733</td>\n      <td>0.499733</td>\n      <td>0.773279</td>\n      <td>0.245495</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>No log</td>\n      <td>0.494885</td>\n      <td>0.494885</td>\n      <td>0.801472</td>\n      <td>0.234234</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>No log</td>\n      <td>0.390006</td>\n      <td>0.390006</td>\n      <td>0.830570</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>No log</td>\n      <td>0.335332</td>\n      <td>0.335332</td>\n      <td>0.854800</td>\n      <td>0.263514</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>No log</td>\n      <td>0.293190</td>\n      <td>0.293190</td>\n      <td>0.877886</td>\n      <td>0.295045</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>No log</td>\n      <td>0.253133</td>\n      <td>0.253133</td>\n      <td>0.892110</td>\n      <td>0.344595</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>No log</td>\n      <td>0.225978</td>\n      <td>0.225978</td>\n      <td>0.904895</td>\n      <td>0.358108</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>No log</td>\n      <td>0.215603</td>\n      <td>0.215603</td>\n      <td>0.920212</td>\n      <td>0.416667</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>No log</td>\n      <td>0.154654</td>\n      <td>0.154654</td>\n      <td>0.936952</td>\n      <td>0.542793</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>No log</td>\n      <td>0.135412</td>\n      <td>0.135412</td>\n      <td>0.947196</td>\n      <td>0.551802</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>No log</td>\n      <td>0.131173</td>\n      <td>0.131173</td>\n      <td>0.958297</td>\n      <td>0.572072</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>No log</td>\n      <td>0.114412</td>\n      <td>0.114412</td>\n      <td>0.960087</td>\n      <td>0.590090</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>No log</td>\n      <td>0.100699</td>\n      <td>0.100699</td>\n      <td>0.961814</td>\n      <td>0.605856</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>No log</td>\n      <td>0.117570</td>\n      <td>0.117570</td>\n      <td>0.966181</td>\n      <td>0.551802</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>No log</td>\n      <td>0.086365</td>\n      <td>0.086288</td>\n      <td>0.971360</td>\n      <td>0.671171</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>No log</td>\n      <td>0.067439</td>\n      <td>0.066958</td>\n      <td>0.976180</td>\n      <td>0.727477</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>No log</td>\n      <td>0.070406</td>\n      <td>0.070042</td>\n      <td>0.973601</td>\n      <td>0.731982</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>No log</td>\n      <td>0.069668</td>\n      <td>0.069510</td>\n      <td>0.977419</td>\n      <td>0.704955</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>No log</td>\n      <td>0.083715</td>\n      <td>0.083712</td>\n      <td>0.975860</td>\n      <td>0.646396</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>No log</td>\n      <td>0.058911</td>\n      <td>0.058888</td>\n      <td>0.979135</td>\n      <td>0.731982</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>No log</td>\n      <td>0.075566</td>\n      <td>0.075250</td>\n      <td>0.975391</td>\n      <td>0.677928</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>No log</td>\n      <td>0.078649</td>\n      <td>0.078294</td>\n      <td>0.975991</td>\n      <td>0.675676</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>No log</td>\n      <td>0.085604</td>\n      <td>0.085280</td>\n      <td>0.978606</td>\n      <td>0.637387</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>No log</td>\n      <td>0.046207</td>\n      <td>0.046205</td>\n      <td>0.982677</td>\n      <td>0.842342</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>No log</td>\n      <td>0.072001</td>\n      <td>0.071926</td>\n      <td>0.978229</td>\n      <td>0.709459</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>No log</td>\n      <td>0.064801</td>\n      <td>0.064393</td>\n      <td>0.981306</td>\n      <td>0.729730</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>No log</td>\n      <td>0.051275</td>\n      <td>0.050972</td>\n      <td>0.983141</td>\n      <td>0.788288</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>No log</td>\n      <td>0.061472</td>\n      <td>0.060987</td>\n      <td>0.982508</td>\n      <td>0.754505</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>No log</td>\n      <td>0.045971</td>\n      <td>0.045476</td>\n      <td>0.985008</td>\n      <td>0.813063</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>No log</td>\n      <td>0.053090</td>\n      <td>0.052541</td>\n      <td>0.983954</td>\n      <td>0.770270</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>No log</td>\n      <td>0.048351</td>\n      <td>0.047890</td>\n      <td>0.984417</td>\n      <td>0.795045</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>No log</td>\n      <td>0.051246</td>\n      <td>0.050874</td>\n      <td>0.983832</td>\n      <td>0.783784</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>No log</td>\n      <td>0.051685</td>\n      <td>0.051289</td>\n      <td>0.983891</td>\n      <td>0.792793</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>No log</td>\n      <td>0.059860</td>\n      <td>0.058965</td>\n      <td>0.983274</td>\n      <td>0.743243</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>No log</td>\n      <td>0.040319</td>\n      <td>0.040029</td>\n      <td>0.986212</td>\n      <td>0.853604</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>No log</td>\n      <td>0.059491</td>\n      <td>0.058760</td>\n      <td>0.983160</td>\n      <td>0.743243</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>No log</td>\n      <td>0.040498</td>\n      <td>0.040051</td>\n      <td>0.986168</td>\n      <td>0.851351</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>No log</td>\n      <td>0.048377</td>\n      <td>0.047704</td>\n      <td>0.985382</td>\n      <td>0.810811</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>No log</td>\n      <td>0.046368</td>\n      <td>0.045858</td>\n      <td>0.985755</td>\n      <td>0.817568</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>No log</td>\n      <td>0.043660</td>\n      <td>0.043255</td>\n      <td>0.986551</td>\n      <td>0.824324</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>No log</td>\n      <td>0.035178</td>\n      <td>0.035043</td>\n      <td>0.987531</td>\n      <td>0.885135</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>No log</td>\n      <td>0.064562</td>\n      <td>0.063860</td>\n      <td>0.983883</td>\n      <td>0.707207</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>No log</td>\n      <td>0.053165</td>\n      <td>0.052223</td>\n      <td>0.984721</td>\n      <td>0.774775</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>No log</td>\n      <td>0.038599</td>\n      <td>0.038019</td>\n      <td>0.987325</td>\n      <td>0.844595</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>No log</td>\n      <td>0.040221</td>\n      <td>0.039556</td>\n      <td>0.987665</td>\n      <td>0.849099</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>No log</td>\n      <td>0.041285</td>\n      <td>0.040445</td>\n      <td>0.987378</td>\n      <td>0.851351</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>No log</td>\n      <td>0.055935</td>\n      <td>0.054707</td>\n      <td>0.984942</td>\n      <td>0.745495</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>No log</td>\n      <td>0.042651</td>\n      <td>0.041944</td>\n      <td>0.986404</td>\n      <td>0.828829</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>No log</td>\n      <td>0.039008</td>\n      <td>0.038499</td>\n      <td>0.986660</td>\n      <td>0.858108</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>No log</td>\n      <td>0.048781</td>\n      <td>0.047962</td>\n      <td>0.985112</td>\n      <td>0.788288</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>No log</td>\n      <td>0.051763</td>\n      <td>0.050878</td>\n      <td>0.984817</td>\n      <td>0.774775</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>No log</td>\n      <td>0.049798</td>\n      <td>0.048970</td>\n      <td>0.985182</td>\n      <td>0.790541</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>No log</td>\n      <td>0.046554</td>\n      <td>0.045810</td>\n      <td>0.985669</td>\n      <td>0.806306</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" Submission saved to: /kaggle/working/submission.csv\n         filename     label\n0   audio_706.wav  1.922620\n1   audio_800.wav  2.361012\n2    audio_68.wav  4.592855\n3  audio_1267.wav  2.886061\n4   audio_683.wav  2.682829\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"\nprint(\"Test dataset features:\", hf_test_dataset.features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T23:07:01.686192Z","iopub.execute_input":"2025-04-06T23:07:01.686540Z","iopub.status.idle":"2025-04-06T23:07:01.691718Z","shell.execute_reply.started":"2025-04-06T23:07:01.686517Z","shell.execute_reply":"2025-04-06T23:07:01.690848Z"}},"outputs":[{"name":"stdout","text":"Test dataset features: {'filename': Value(dtype='string', id=None), 'audio_path': {'bytes': Value(dtype='binary', id=None), 'path': Value(dtype='null', id=None)}, 'text': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"### Approach -2","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import BertTokenizer, TrainingArguments, Trainer, BertPreTrainedModel, BertModel\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport torch.nn as nn\nfrom transformers.modeling_outputs import SequenceClassifierOutput\n\n\n# Convert to HuggingFace datasets\nhf_train_dataset = Dataset.from_pandas(train_df_with_text)\nhf_test_dataset = Dataset.from_pandas(test_df_with_text)\n\n# =============================================\n# 2. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nhf_train_dataset = hf_train_dataset.map(tokenize, batched=True)\nhf_test_dataset = hf_test_dataset.map(tokenize, batched=True)\n\nhf_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nhf_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. BERT Model for Regression (Frozen Base)\n# =============================================\nclass BertRegressionModel(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n\n        # Freeze all BERT layers\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n        # Unfreeze last 4 layers and pooler\n        for layer in self.bert.encoder.layer[-4:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        for param in self.bert.pooler.parameters():\n            param.requires_grad = True\n\n        self.regressor = nn.Sequential(\n            nn.Linear(config.hidden_size, 512),\n            nn.LayerNorm(512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n\n            nn.Linear(512, 256),\n            nn.LayerNorm(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        \n        # Mean pooling instead of CLS token\n        last_hidden_state = outputs.last_hidden_state\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n        mean_pooled = sum_embeddings / sum_mask\n\n        logits = self.regressor(mean_pooled).squeeze(-1)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.MSELoss()\n            loss = loss_fn(logits, labels.float())\n\n        return SequenceClassifierOutput(loss=loss, logits=logits)\nmodel = BertRegressionModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 4. Metrics (Regression + Accuracy)\n# =============================================\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.flatten()\n    labels = labels.flatten()\n    predictions = np.clip(predictions, 0, 5)\n\n    # Accuracy after rounding to nearest 0.5\n    pred_rounded = np.round(predictions * 2) / 2\n    label_rounded = np.round(labels * 2) / 2\n    accuracy = np.mean(pred_rounded == label_rounded)\n\n    return {\n        \"mse\": mean_squared_error(labels, predictions),\n        \"pearson\": pearsonr(predictions, labels)[0],\n        \"accuracy\": accuracy\n    }\n\n# =============================================\n# 5. Training Arguments\n# =============================================\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=64,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    # load_best_model_at_end=True,\n    # metric_for_best_model=\"pearson\",\n    # greater_is_better=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\n# =============================================\n# 6. Trainer Setup\n# =============================================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=hf_train_dataset,\n    eval_dataset=hf_train_dataset,  # Use validation set if available\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 7. Train the Model\n# =============================================\ntrainer.train()\n\n# # =============================================\n# # 8. Inference on Test Set\n# # =============================================\n# predictions = trainer.predict(hf_test_dataset)\n# predicted_scores = np.clip(predictions.predictions.flatten(), 0, 5)\n\n# # =============================================\n# # 9. Submission File\n# # =============================================\n# submission = pd.DataFrame({\n#     \"filename\": test_df[\"filename\"],\n#     \"label\": predicted_scores\n# })\n\n# submission_path = \"/kaggle/working/submission.csv\"\n# submission.to_csv(submission_path, index=False)\n\n# if os.path.exists(submission_path):\n#     print(f\" Submission saved to: {submission_path}\")\n#     print(submission.head())\n# else:\n#     print(\" Error: Submission file not saved!\")\n\n# =============================================\n# 8. Inference on Test Set (Corrected)\n# =============================================\n\n# 1. First, make sure the test dataset has the right format (only input features)\nhf_test_dataset.set_format(\n    type=\"torch\", \n    columns=[\"input_ids\", \"attention_mask\"]  # No labels needed\n)\n\n# 2. Create a custom prediction function\ndef predict_without_labels(model, dataset):\n    model.eval()\n    predictions = []\n    \n    # Create dataloader\n    dataloader = torch.utils.data.DataLoader(\n        dataset, \n        batch_size=training_args.per_device_eval_batch_size\n    )\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            # Move batch to GPU\n            inputs = {\n                'input_ids': batch['input_ids'].to('cuda'),\n                'attention_mask': batch['attention_mask'].to('cuda')\n            }\n            \n            # Forward pass\n            outputs = model(**inputs)\n            predictions.append(outputs['logits'].cpu().numpy())\n    \n    return np.concatenate(predictions, axis=0)\n\n# 3. Run prediction\npredicted_scores = predict_without_labels(model, hf_test_dataset)\npredicted_scores = np.clip(predicted_scores.flatten(), 0, 5)\n# =============================================\n# 9. Submission File\n# =============================================\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n\nif os.path.exists(submission_path):\n    print(f\" Submission saved to: {submission_path}\")\n    print(submission.head())\nelse:\n    print(\" Error: Submission file not saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T23:33:58.598707Z","iopub.execute_input":"2025-04-06T23:33:58.599036Z","iopub.status.idle":"2025-04-06T23:39:55.748159Z","shell.execute_reply.started":"2025-04-06T23:33:58.599013Z","shell.execute_reply":"2025-04-06T23:39:55.747211Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc87f234bcb1416e995e04950db97590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dff64808176e4c5b9941a3fecbe1424b"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertRegressionModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['regressor.0.bias', 'regressor.0.weight', 'regressor.1.bias', 'regressor.1.weight', 'regressor.4.bias', 'regressor.4.weight', 'regressor.5.bias', 'regressor.5.weight', 'regressor.8.bias', 'regressor.8.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='448' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [448/448 05:37, Epoch 64/64]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mse</th>\n      <th>Pearson</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>3.714662</td>\n      <td>3.714661</td>\n      <td>0.139329</td>\n      <td>0.150901</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>2.062696</td>\n      <td>2.062696</td>\n      <td>0.053326</td>\n      <td>0.092342</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.586926</td>\n      <td>1.586925</td>\n      <td>0.139561</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.424692</td>\n      <td>1.424692</td>\n      <td>0.151428</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.345661</td>\n      <td>1.345661</td>\n      <td>0.177533</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.305839</td>\n      <td>1.305839</td>\n      <td>0.206875</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.278975</td>\n      <td>1.278975</td>\n      <td>0.210682</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.258077</td>\n      <td>1.258077</td>\n      <td>0.271223</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.228281</td>\n      <td>1.228281</td>\n      <td>0.361323</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>1.124773</td>\n      <td>1.124773</td>\n      <td>0.557352</td>\n      <td>0.087838</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>0.953876</td>\n      <td>0.953876</td>\n      <td>0.610548</td>\n      <td>0.092342</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>No log</td>\n      <td>0.968579</td>\n      <td>0.968579</td>\n      <td>0.548225</td>\n      <td>0.083333</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>No log</td>\n      <td>0.861387</td>\n      <td>0.861387</td>\n      <td>0.716263</td>\n      <td>0.110360</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>No log</td>\n      <td>0.872482</td>\n      <td>0.872482</td>\n      <td>0.670112</td>\n      <td>0.114865</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>No log</td>\n      <td>0.757662</td>\n      <td>0.757662</td>\n      <td>0.722902</td>\n      <td>0.123874</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>No log</td>\n      <td>0.740697</td>\n      <td>0.740697</td>\n      <td>0.710629</td>\n      <td>0.117117</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>No log</td>\n      <td>0.700614</td>\n      <td>0.700614</td>\n      <td>0.736384</td>\n      <td>0.213964</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>No log</td>\n      <td>0.653898</td>\n      <td>0.653898</td>\n      <td>0.765114</td>\n      <td>0.238739</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>No log</td>\n      <td>0.620898</td>\n      <td>0.620898</td>\n      <td>0.780587</td>\n      <td>0.245495</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>No log</td>\n      <td>0.580558</td>\n      <td>0.580558</td>\n      <td>0.792499</td>\n      <td>0.277027</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>No log</td>\n      <td>0.554823</td>\n      <td>0.554823</td>\n      <td>0.806690</td>\n      <td>0.256757</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>No log</td>\n      <td>0.543159</td>\n      <td>0.543159</td>\n      <td>0.791198</td>\n      <td>0.256757</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>No log</td>\n      <td>0.512994</td>\n      <td>0.512994</td>\n      <td>0.820743</td>\n      <td>0.254505</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>No log</td>\n      <td>0.538264</td>\n      <td>0.538264</td>\n      <td>0.781703</td>\n      <td>0.234234</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>No log</td>\n      <td>0.448589</td>\n      <td>0.448589</td>\n      <td>0.850144</td>\n      <td>0.290541</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>No log</td>\n      <td>0.430049</td>\n      <td>0.430049</td>\n      <td>0.840747</td>\n      <td>0.319820</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>No log</td>\n      <td>0.401181</td>\n      <td>0.401181</td>\n      <td>0.875512</td>\n      <td>0.351351</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>No log</td>\n      <td>0.428963</td>\n      <td>0.428963</td>\n      <td>0.849545</td>\n      <td>0.270270</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>No log</td>\n      <td>0.369595</td>\n      <td>0.369594</td>\n      <td>0.871656</td>\n      <td>0.324324</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>No log</td>\n      <td>0.344007</td>\n      <td>0.344007</td>\n      <td>0.881921</td>\n      <td>0.378378</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>No log</td>\n      <td>0.354651</td>\n      <td>0.354651</td>\n      <td>0.870229</td>\n      <td>0.324324</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>No log</td>\n      <td>0.329148</td>\n      <td>0.329148</td>\n      <td>0.880596</td>\n      <td>0.364865</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>No log</td>\n      <td>0.292144</td>\n      <td>0.292144</td>\n      <td>0.898716</td>\n      <td>0.436937</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>No log</td>\n      <td>0.313232</td>\n      <td>0.313232</td>\n      <td>0.890653</td>\n      <td>0.335586</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>No log</td>\n      <td>0.293081</td>\n      <td>0.293081</td>\n      <td>0.898787</td>\n      <td>0.351351</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>No log</td>\n      <td>0.255638</td>\n      <td>0.255638</td>\n      <td>0.914170</td>\n      <td>0.432432</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>No log</td>\n      <td>0.244643</td>\n      <td>0.244643</td>\n      <td>0.924958</td>\n      <td>0.423423</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>No log</td>\n      <td>0.237893</td>\n      <td>0.237893</td>\n      <td>0.918245</td>\n      <td>0.484234</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>No log</td>\n      <td>0.234819</td>\n      <td>0.234819</td>\n      <td>0.914045</td>\n      <td>0.488739</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>No log</td>\n      <td>0.222451</td>\n      <td>0.222451</td>\n      <td>0.919479</td>\n      <td>0.509009</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>No log</td>\n      <td>0.203446</td>\n      <td>0.203446</td>\n      <td>0.930020</td>\n      <td>0.567568</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>No log</td>\n      <td>0.216149</td>\n      <td>0.216149</td>\n      <td>0.922275</td>\n      <td>0.443694</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>No log</td>\n      <td>0.186471</td>\n      <td>0.186471</td>\n      <td>0.934082</td>\n      <td>0.585586</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>No log</td>\n      <td>0.210763</td>\n      <td>0.210763</td>\n      <td>0.926493</td>\n      <td>0.403153</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>No log</td>\n      <td>0.197612</td>\n      <td>0.197612</td>\n      <td>0.923102</td>\n      <td>0.504505</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>No log</td>\n      <td>0.177581</td>\n      <td>0.177581</td>\n      <td>0.935961</td>\n      <td>0.581081</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>No log</td>\n      <td>0.188911</td>\n      <td>0.188911</td>\n      <td>0.931036</td>\n      <td>0.497748</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>No log</td>\n      <td>0.182548</td>\n      <td>0.182548</td>\n      <td>0.930223</td>\n      <td>0.522523</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>No log</td>\n      <td>0.165386</td>\n      <td>0.165386</td>\n      <td>0.938103</td>\n      <td>0.572072</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>No log</td>\n      <td>0.178946</td>\n      <td>0.178946</td>\n      <td>0.936189</td>\n      <td>0.468468</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>No log</td>\n      <td>0.154179</td>\n      <td>0.154179</td>\n      <td>0.942664</td>\n      <td>0.587838</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>No log</td>\n      <td>0.172552</td>\n      <td>0.172552</td>\n      <td>0.936199</td>\n      <td>0.479730</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>No log</td>\n      <td>0.151637</td>\n      <td>0.151637</td>\n      <td>0.941101</td>\n      <td>0.581081</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>No log</td>\n      <td>0.162886</td>\n      <td>0.162886</td>\n      <td>0.936695</td>\n      <td>0.531532</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>No log</td>\n      <td>0.148177</td>\n      <td>0.148177</td>\n      <td>0.943935</td>\n      <td>0.574324</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>No log</td>\n      <td>0.156313</td>\n      <td>0.156313</td>\n      <td>0.943305</td>\n      <td>0.520270</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>No log</td>\n      <td>0.147477</td>\n      <td>0.147477</td>\n      <td>0.946031</td>\n      <td>0.554054</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>No log</td>\n      <td>0.146778</td>\n      <td>0.146778</td>\n      <td>0.945409</td>\n      <td>0.560811</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>No log</td>\n      <td>0.142032</td>\n      <td>0.142032</td>\n      <td>0.945465</td>\n      <td>0.572072</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>No log</td>\n      <td>0.141681</td>\n      <td>0.141681</td>\n      <td>0.945476</td>\n      <td>0.567568</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>No log</td>\n      <td>0.152278</td>\n      <td>0.152278</td>\n      <td>0.941722</td>\n      <td>0.509009</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>No log</td>\n      <td>0.138946</td>\n      <td>0.138946</td>\n      <td>0.946173</td>\n      <td>0.576577</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>No log</td>\n      <td>0.138907</td>\n      <td>0.138907</td>\n      <td>0.946379</td>\n      <td>0.569820</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>No log</td>\n      <td>0.139707</td>\n      <td>0.139707</td>\n      <td>0.946220</td>\n      <td>0.560811</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" Submission saved to: /kaggle/working/submission.csv\n         filename     label\n0   audio_706.wav  1.899576\n1   audio_800.wav  1.972397\n2    audio_68.wav  3.915667\n3  audio_1267.wav  3.184306\n4   audio_683.wav  2.690701\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"### Approach -3","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import BertTokenizer, TrainingArguments, Trainer, BertPreTrainedModel, BertModel\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport torch.nn as nn\n\n\n\n# Convert to HuggingFace datasets\nhf_train_dataset = Dataset.from_pandas(train_df_with_text)\nhf_test_dataset = Dataset.from_pandas(test_df_with_text)\n\n# =============================================\n# 2. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nhf_train_dataset = hf_train_dataset.map(tokenize, batched=True)\nhf_test_dataset = hf_test_dataset.map(tokenize, batched=True)\n\nhf_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nhf_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. BERT Model for Regression (Frozen Base)\n# =============================================\nclass BertRegressionModel(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n        \n        # Freeze all layers initially\n        for param in self.bert.parameters():\n            param.requires_grad = False\n            \n        # Unfreeze last 3 encoder layers + pooler\n        for layer in self.bert.encoder.layer[-3:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        for param in self.bert.pooler.parameters():\n            param.requires_grad = True\n            \n        # Enhanced regression head with layer normalization and more capacity\n        self.regressor = nn.Sequential(\n            nn.Linear(config.hidden_size, 512),  # Note: Using single hidden_size now\n            nn.LayerNorm(512),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            \n            nn.Linear(512, 256),\n            nn.LayerNorm(256),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            \n            nn.Linear(256, 128),\n            nn.LayerNorm(128),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            \n            nn.Linear(128, 1)\n        )\n        \n        self.init_weights()\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            output_hidden_states=True\n        )\n        \n        # Using just the last hidden state's [CLS] token representation\n        # (equivalent to pooler_output but gives you more control)\n        last_hidden_state = outputs.last_hidden_state\n        cls_token = last_hidden_state[:, 0, :]  # Take [CLS] token\n        \n        logits = self.regressor(cls_token).squeeze(-1)\n        \n        loss = None\n        if labels is not None:\n            loss_fn = nn.SmoothL1Loss()\n            loss = loss_fn(logits, labels.float())\n            \n            # L2 regularization\n            l2_lambda = 0.01\n            l2_norm = sum(p.pow(2.0).sum() for p in self.regressor.parameters())\n            loss = loss + l2_lambda * l2_norm\n\n        return {\"loss\": loss, \"logits\": logits}\n\nmodel = BertRegressionModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 4. Metrics (Regression + Accuracy)\n# =============================================\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.flatten()\n    labels = labels.flatten()\n    predictions = np.clip(predictions, 0, 5)\n\n    # Accuracy after rounding to nearest 0.5\n    pred_rounded = np.round(predictions * 2) / 2\n    label_rounded = np.round(labels * 2) / 2\n    accuracy = np.mean(pred_rounded == label_rounded)\n\n    return {\n        \"mse\": mean_squared_error(labels, predictions),\n        \"pearson\": pearsonr(predictions, labels)[0],\n        \"accuracy\": accuracy\n    }\n\n# =============================================\n# 5. Training Arguments\n# =============================================\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,  # Larger batch for evaluation\n    num_train_epochs=40,            # Reduced epochs (can use early stopping)\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"pearson\",\n    greater_is_better=True,\n    fp16=True,\n    report_to=\"none\",\n    learning_rate=3e-5,             # Adjusted learning rate\n    weight_decay=0.01,              # Explicit weight decay\n    warmup_ratio=0.1,               # Learning rate warmup\n    gradient_accumulation_steps=2,  # For more stable training\n    save_total_limit=2,             # Keep only best models\n)\n\n# =============================================\n# 6. Trainer Setup\n# =============================================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=hf_train_dataset,\n    eval_dataset=hf_train_dataset,  # Use validation set if available\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 7. Train the Model\n# =============================================\ntrainer.train()\n\n# # =============================================\n# # 8. Inference on Test Set\n# # =============================================\n# predictions = trainer.predict(hf_test_dataset)\n# predicted_scores = np.clip(predictions.predictions.flatten(), 0, 5)\n\n# # =============================================\n# # 9. Submission File\n# # =============================================\n# submission = pd.DataFrame({\n#     \"filename\": test_df[\"filename\"],\n#     \"label\": predicted_scores\n# })\n\n# submission_path = \"/kaggle/working/submission.csv\"\n# submission.to_csv(submission_path, index=False)\n\n# if os.path.exists(submission_path):\n#     print(f\" Submission saved to: {submission_path}\")\n#     print(submission.head())\n# else:\n#     print(\" Error: Submission file not saved!\")\n\n# =============================================\n# 8. Inference on Test Set (Corrected)\n# =============================================\n\n# 1. First, make sure the test dataset has the right format (only input features)\nhf_test_dataset.set_format(\n    type=\"torch\", \n    columns=[\"input_ids\", \"attention_mask\"]  # No labels needed\n)\n\n# 2. Create a custom prediction function\ndef predict_without_labels(model, dataset):\n    model.eval()\n    predictions = []\n    \n    # Create dataloader\n    dataloader = torch.utils.data.DataLoader(\n        dataset, \n        batch_size=training_args.per_device_eval_batch_size\n    )\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            # Move batch to GPU\n            inputs = {\n                'input_ids': batch['input_ids'].to('cuda'),\n                'attention_mask': batch['attention_mask'].to('cuda')\n            }\n            \n            # Forward pass\n            outputs = model(**inputs)\n            predictions.append(outputs['logits'].cpu().numpy())\n    \n    return np.concatenate(predictions, axis=0)\n\n# 3. Run prediction\npredicted_scores = predict_without_labels(model, hf_test_dataset)\npredicted_scores = np.clip(predicted_scores.flatten(), 0, 5)\n# =============================================\n# 9. Submission File\n# =============================================\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n\nif os.path.exists(submission_path):\n    print(f\" Submission saved to: {submission_path}\")\n    print(submission.head())\nelse:\n    print(\" Error: Submission file not saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T23:53:39.964312Z","iopub.execute_input":"2025-04-06T23:53:39.964670Z","iopub.status.idle":"2025-04-06T23:57:07.727320Z","shell.execute_reply.started":"2025-04-06T23:53:39.964645Z","shell.execute_reply":"2025-04-06T23:57:07.726374Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfeca9d78ae747a58bf2a06e67cb16ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4cc311b3c04408a4ea358d1157d9ed"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertRegressionModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['regressor.0.bias', 'regressor.0.weight', 'regressor.1.bias', 'regressor.1.weight', 'regressor.12.bias', 'regressor.12.weight', 'regressor.4.bias', 'regressor.4.weight', 'regressor.5.bias', 'regressor.5.weight', 'regressor.8.bias', 'regressor.8.weight', 'regressor.9.bias', 'regressor.9.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [120/120 03:07, Epoch 30/40]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mse</th>\n      <th>Pearson</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.733400</td>\n      <td>8.650088</td>\n      <td>13.788647</td>\n      <td>0.086535</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.607400</td>\n      <td>8.297031</td>\n      <td>11.515423</td>\n      <td>-0.129747</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.364600</td>\n      <td>7.951439</td>\n      <td>9.393885</td>\n      <td>-0.007187</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.110200</td>\n      <td>7.709852</td>\n      <td>8.058847</td>\n      <td>0.046874</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.935200</td>\n      <td>7.549747</td>\n      <td>7.230450</td>\n      <td>0.067061</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.825500</td>\n      <td>7.440984</td>\n      <td>6.686299</td>\n      <td>0.087715</td>\n      <td>0.004505</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.739700</td>\n      <td>7.362116</td>\n      <td>6.302498</td>\n      <td>0.095855</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.677900</td>\n      <td>7.301018</td>\n      <td>6.011431</td>\n      <td>0.098177</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.642900</td>\n      <td>7.253753</td>\n      <td>5.790096</td>\n      <td>0.097604</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.591000</td>\n      <td>7.217873</td>\n      <td>5.623953</td>\n      <td>0.098937</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.556400</td>\n      <td>7.189883</td>\n      <td>5.495398</td>\n      <td>0.093308</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.550800</td>\n      <td>7.167291</td>\n      <td>5.392247</td>\n      <td>0.085203</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.522600</td>\n      <td>7.148162</td>\n      <td>5.305229</td>\n      <td>0.079296</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.508200</td>\n      <td>7.131983</td>\n      <td>5.231855</td>\n      <td>0.075212</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.477600</td>\n      <td>7.117794</td>\n      <td>5.167577</td>\n      <td>0.077110</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.468200</td>\n      <td>7.105156</td>\n      <td>5.110507</td>\n      <td>0.078867</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.451200</td>\n      <td>7.094099</td>\n      <td>5.060687</td>\n      <td>0.079919</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.443400</td>\n      <td>7.084363</td>\n      <td>5.016955</td>\n      <td>0.078892</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.431200</td>\n      <td>7.075960</td>\n      <td>4.979261</td>\n      <td>0.080011</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.442100</td>\n      <td>7.068854</td>\n      <td>4.947417</td>\n      <td>0.083494</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.416200</td>\n      <td>7.062679</td>\n      <td>4.919807</td>\n      <td>0.085545</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.416200</td>\n      <td>7.057307</td>\n      <td>4.895816</td>\n      <td>0.087863</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.410500</td>\n      <td>7.052797</td>\n      <td>4.875697</td>\n      <td>0.089229</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.411100</td>\n      <td>7.049013</td>\n      <td>4.858860</td>\n      <td>0.088201</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.400900</td>\n      <td>7.045949</td>\n      <td>4.845240</td>\n      <td>0.087252</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.402100</td>\n      <td>7.043368</td>\n      <td>4.833779</td>\n      <td>0.086067</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.395400</td>\n      <td>7.041306</td>\n      <td>4.824626</td>\n      <td>0.084988</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.411500</td>\n      <td>7.039824</td>\n      <td>4.818050</td>\n      <td>0.084337</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.386800</td>\n      <td>7.038945</td>\n      <td>4.814147</td>\n      <td>0.084349</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.392600</td>\n      <td>7.038613</td>\n      <td>4.812673</td>\n      <td>0.084385</td>\n      <td>0.006757</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" Submission saved to: /kaggle/working/submission.csv\n         filename     label\n0   audio_706.wav  1.485572\n1   audio_800.wav  1.528615\n2    audio_68.wav  1.532290\n3  audio_1267.wav  1.522899\n4   audio_683.wav  1.527562\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"### Approach -4","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import BertTokenizer, TrainingArguments, Trainer, BertPreTrainedModel, BertModel\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport torch.nn as nn\n\n\n\n# Convert to HuggingFace datasets\nhf_train_dataset = Dataset.from_pandas(train_df_with_text)\nhf_test_dataset = Dataset.from_pandas(test_df_with_text)\n\n# =============================================\n# 2. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nhf_train_dataset = hf_train_dataset.map(tokenize, batched=True)\nhf_test_dataset = hf_test_dataset.map(tokenize, batched=True)\n\nhf_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nhf_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. BERT Model for Regression (Frozen Base)\n# =============================================\nclass BertRegressionModel(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n\n        # Freeze all layers\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n        # Unfreeze last 2 encoder layers + pooler\n        for layer in self.bert.encoder.layer[-2:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        for param in self.bert.pooler.parameters():\n            param.requires_grad = True\n\n        self.regressor = nn.Sequential(\n            nn.Linear(config.hidden_size, 512),\n            nn.LayerNorm(512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n        \n            nn.Linear(512, 256),\n            nn.LayerNorm(256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n        \n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n        \n            nn.Linear(64, 1)\n        )\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        logits = self.regressor(pooled_output).squeeze(-1)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.MSELoss()\n            loss = loss_fn(logits, labels.float())\n\n        return {\"loss\": loss, \"logits\": logits}\n\nmodel = BertRegressionModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 4. Metrics (Regression + Accuracy)\n# =============================================\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.flatten()\n    labels = labels.flatten()\n    predictions = np.clip(predictions, 0, 5)\n\n    # Accuracy after rounding to nearest 0.5\n    pred_rounded = np.round(predictions * 2) / 2\n    label_rounded = np.round(labels * 2) / 2\n    accuracy = np.mean(pred_rounded == label_rounded)\n\n    return {\n        \"mse\": mean_squared_error(labels, predictions),\n        \"pearson\": pearsonr(predictions, labels)[0],\n        \"accuracy\": accuracy\n    }\n\n# =============================================\n# 5. Training Arguments\n# =============================================\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=256,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    # load_best_model_at_end=True,\n    # metric_for_best_model=\"pearson\",\n    # greater_is_better=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\n# =============================================\n# 6. Trainer Setup\n# =============================================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=hf_train_dataset,\n    eval_dataset=hf_train_dataset,  # Use validation set if available\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 7. Train the Model\n# =============================================\ntrainer.train()\n\n# # =============================================\n# # 8. Inference on Test Set\n# # =============================================\n# predictions = trainer.predict(hf_test_dataset)\n# predicted_scores = np.clip(predictions.predictions.flatten(), 0, 5)\n\n# # =============================================\n# # 9. Submission File\n# # =============================================\n# submission = pd.DataFrame({\n#     \"filename\": test_df[\"filename\"],\n#     \"label\": predicted_scores\n# })\n\n# submission_path = \"/kaggle/working/submission.csv\"\n# submission.to_csv(submission_path, index=False)\n\n# if os.path.exists(submission_path):\n#     print(f\" Submission saved to: {submission_path}\")\n#     print(submission.head())\n# else:\n#     print(\" Error: Submission file not saved!\")\n\n# =============================================\n# 8. Inference on Test Set (Corrected)\n# =============================================\n\n# 1. First, make sure the test dataset has the right format (only input features)\nhf_test_dataset.set_format(\n    type=\"torch\", \n    columns=[\"input_ids\", \"attention_mask\"]  # No labels needed\n)\n\n# 2. Create a custom prediction function\ndef predict_without_labels(model, dataset):\n    model.eval()\n    predictions = []\n    \n    # Create dataloader\n    dataloader = torch.utils.data.DataLoader(\n        dataset, \n        batch_size=training_args.per_device_eval_batch_size\n    )\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            # Move batch to GPU\n            inputs = {\n                'input_ids': batch['input_ids'].to('cuda'),\n                'attention_mask': batch['attention_mask'].to('cuda')\n            }\n            \n            # Forward pass\n            outputs = model(**inputs)\n            predictions.append(outputs['logits'].cpu().numpy())\n    \n    return np.concatenate(predictions, axis=0)\n\n# 3. Run prediction\npredicted_scores = predict_without_labels(model, hf_test_dataset)\npredicted_scores = np.clip(predicted_scores.flatten(), 0, 5)\n# =============================================\n# 9. Submission File\n# =============================================\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n\nif os.path.exists(submission_path):\n    print(f\" Submission saved to: {submission_path}\")\n    print(submission.head())\nelse:\n    print(\" Error: Submission file not saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:21:32.015811Z","iopub.execute_input":"2025-04-07T00:21:32.016137Z","iopub.status.idle":"2025-04-07T00:41:52.518127Z","shell.execute_reply.started":"2025-04-07T00:21:32.016108Z","shell.execute_reply":"2025-04-07T00:41:52.517256Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b0475720184eb8be33e1456b069d8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2beb26a2d66044b7b1f8c960555a04a2"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertRegressionModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['regressor.0.bias', 'regressor.0.weight', 'regressor.1.bias', 'regressor.1.weight', 'regressor.11.bias', 'regressor.11.weight', 'regressor.4.bias', 'regressor.4.weight', 'regressor.5.bias', 'regressor.5.weight', 'regressor.8.bias', 'regressor.8.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1792' max='1792' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1792/1792 19:57, Epoch 256/256]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mse</th>\n      <th>Pearson</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>13.370345</td>\n      <td>13.370344</td>\n      <td>-0.013619</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>12.577592</td>\n      <td>12.577592</td>\n      <td>0.025159</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>12.019942</td>\n      <td>12.019942</td>\n      <td>0.082255</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>11.620266</td>\n      <td>11.620267</td>\n      <td>0.097893</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>11.255843</td>\n      <td>11.255842</td>\n      <td>0.080286</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>10.923291</td>\n      <td>10.923291</td>\n      <td>0.046035</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>10.603070</td>\n      <td>10.603069</td>\n      <td>0.072765</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>10.285638</td>\n      <td>10.285638</td>\n      <td>0.089789</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>9.973025</td>\n      <td>9.973027</td>\n      <td>0.095646</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>9.659416</td>\n      <td>9.659416</td>\n      <td>0.067053</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>9.354292</td>\n      <td>9.354292</td>\n      <td>0.082427</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>No log</td>\n      <td>9.056503</td>\n      <td>9.056503</td>\n      <td>0.079159</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>No log</td>\n      <td>8.757623</td>\n      <td>8.757623</td>\n      <td>0.096039</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>No log</td>\n      <td>8.462440</td>\n      <td>8.462440</td>\n      <td>0.109817</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>No log</td>\n      <td>8.171857</td>\n      <td>8.171855</td>\n      <td>0.099903</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>No log</td>\n      <td>7.885279</td>\n      <td>7.885280</td>\n      <td>0.109096</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>No log</td>\n      <td>7.602130</td>\n      <td>7.602129</td>\n      <td>0.118776</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>No log</td>\n      <td>7.323937</td>\n      <td>7.323936</td>\n      <td>0.123565</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>No log</td>\n      <td>7.049057</td>\n      <td>7.049058</td>\n      <td>0.093096</td>\n      <td>0.002252</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>No log</td>\n      <td>6.778223</td>\n      <td>6.778221</td>\n      <td>0.049402</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>No log</td>\n      <td>6.508698</td>\n      <td>6.508697</td>\n      <td>0.055239</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>No log</td>\n      <td>6.242544</td>\n      <td>6.242545</td>\n      <td>0.012503</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>No log</td>\n      <td>5.981658</td>\n      <td>5.981658</td>\n      <td>0.017375</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>No log</td>\n      <td>5.724731</td>\n      <td>5.724731</td>\n      <td>0.051386</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>No log</td>\n      <td>5.472615</td>\n      <td>5.472614</td>\n      <td>0.080380</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>No log</td>\n      <td>5.225917</td>\n      <td>5.225917</td>\n      <td>0.110624</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>No log</td>\n      <td>4.984554</td>\n      <td>4.984554</td>\n      <td>0.098213</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>No log</td>\n      <td>4.749191</td>\n      <td>4.749191</td>\n      <td>0.077277</td>\n      <td>0.006757</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>No log</td>\n      <td>4.519829</td>\n      <td>4.519830</td>\n      <td>0.056478</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>No log</td>\n      <td>4.296466</td>\n      <td>4.296467</td>\n      <td>0.048531</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>No log</td>\n      <td>4.078848</td>\n      <td>4.078849</td>\n      <td>0.087471</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>No log</td>\n      <td>3.867512</td>\n      <td>3.867512</td>\n      <td>0.101417</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>No log</td>\n      <td>3.662755</td>\n      <td>3.662755</td>\n      <td>0.105494</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>No log</td>\n      <td>3.464315</td>\n      <td>3.464315</td>\n      <td>0.071035</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>No log</td>\n      <td>3.272578</td>\n      <td>3.272579</td>\n      <td>0.038451</td>\n      <td>0.157658</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>No log</td>\n      <td>3.088376</td>\n      <td>3.088376</td>\n      <td>0.030485</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>No log</td>\n      <td>2.911962</td>\n      <td>2.911962</td>\n      <td>0.045302</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>No log</td>\n      <td>2.742265</td>\n      <td>2.742265</td>\n      <td>0.065384</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>No log</td>\n      <td>2.580455</td>\n      <td>2.580455</td>\n      <td>0.093675</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>No log</td>\n      <td>2.427294</td>\n      <td>2.427294</td>\n      <td>0.115506</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>No log</td>\n      <td>2.282707</td>\n      <td>2.282707</td>\n      <td>0.142626</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>No log</td>\n      <td>2.146401</td>\n      <td>2.146401</td>\n      <td>0.136235</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>No log</td>\n      <td>2.018704</td>\n      <td>2.018704</td>\n      <td>0.106007</td>\n      <td>0.090090</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>No log</td>\n      <td>1.899461</td>\n      <td>1.899461</td>\n      <td>0.070021</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>No log</td>\n      <td>1.789773</td>\n      <td>1.789773</td>\n      <td>0.074356</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>No log</td>\n      <td>1.689895</td>\n      <td>1.689895</td>\n      <td>0.052332</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>No log</td>\n      <td>1.599877</td>\n      <td>1.599877</td>\n      <td>0.064065</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>No log</td>\n      <td>1.519106</td>\n      <td>1.519106</td>\n      <td>0.100171</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>No log</td>\n      <td>1.448889</td>\n      <td>1.448889</td>\n      <td>0.118554</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>No log</td>\n      <td>1.388828</td>\n      <td>1.388828</td>\n      <td>0.148860</td>\n      <td>0.195946</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>No log</td>\n      <td>1.339085</td>\n      <td>1.339085</td>\n      <td>0.146574</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>No log</td>\n      <td>1.299365</td>\n      <td>1.299365</td>\n      <td>0.151949</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>No log</td>\n      <td>1.271159</td>\n      <td>1.271158</td>\n      <td>0.247271</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>No log</td>\n      <td>1.253308</td>\n      <td>1.253308</td>\n      <td>0.391978</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>No log</td>\n      <td>1.244070</td>\n      <td>1.244070</td>\n      <td>0.627478</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>No log</td>\n      <td>1.235281</td>\n      <td>1.235281</td>\n      <td>0.654328</td>\n      <td>0.051802</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>No log</td>\n      <td>1.139186</td>\n      <td>1.139186</td>\n      <td>0.632487</td>\n      <td>0.065315</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>No log</td>\n      <td>0.931388</td>\n      <td>0.931388</td>\n      <td>0.570645</td>\n      <td>0.117117</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>No log</td>\n      <td>0.837018</td>\n      <td>0.837018</td>\n      <td>0.654744</td>\n      <td>0.114865</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>No log</td>\n      <td>0.746387</td>\n      <td>0.746387</td>\n      <td>0.754677</td>\n      <td>0.229730</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>No log</td>\n      <td>0.653132</td>\n      <td>0.653132</td>\n      <td>0.754593</td>\n      <td>0.218468</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>No log</td>\n      <td>0.581515</td>\n      <td>0.581515</td>\n      <td>0.776853</td>\n      <td>0.236486</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>No log</td>\n      <td>0.582689</td>\n      <td>0.582689</td>\n      <td>0.778374</td>\n      <td>0.225225</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>No log</td>\n      <td>0.465673</td>\n      <td>0.465673</td>\n      <td>0.819959</td>\n      <td>0.286036</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>No log</td>\n      <td>0.403552</td>\n      <td>0.403552</td>\n      <td>0.859232</td>\n      <td>0.324324</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>No log</td>\n      <td>0.348713</td>\n      <td>0.348713</td>\n      <td>0.872553</td>\n      <td>0.331081</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>No log</td>\n      <td>0.379677</td>\n      <td>0.379677</td>\n      <td>0.855574</td>\n      <td>0.281532</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>No log</td>\n      <td>0.278227</td>\n      <td>0.278227</td>\n      <td>0.893090</td>\n      <td>0.445946</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>No log</td>\n      <td>0.258991</td>\n      <td>0.258991</td>\n      <td>0.899344</td>\n      <td>0.443694</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>No log</td>\n      <td>0.238281</td>\n      <td>0.238281</td>\n      <td>0.902695</td>\n      <td>0.394144</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>No log</td>\n      <td>0.195329</td>\n      <td>0.195329</td>\n      <td>0.924564</td>\n      <td>0.436937</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>4.681500</td>\n      <td>0.214386</td>\n      <td>0.214386</td>\n      <td>0.920271</td>\n      <td>0.369369</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>4.681500</td>\n      <td>0.173026</td>\n      <td>0.173026</td>\n      <td>0.929821</td>\n      <td>0.445946</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>4.681500</td>\n      <td>0.151638</td>\n      <td>0.151638</td>\n      <td>0.937629</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>4.681500</td>\n      <td>0.181641</td>\n      <td>0.181641</td>\n      <td>0.935329</td>\n      <td>0.391892</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>4.681500</td>\n      <td>0.141381</td>\n      <td>0.141381</td>\n      <td>0.942869</td>\n      <td>0.486486</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>4.681500</td>\n      <td>0.129646</td>\n      <td>0.129646</td>\n      <td>0.947926</td>\n      <td>0.524775</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>4.681500</td>\n      <td>0.132330</td>\n      <td>0.132330</td>\n      <td>0.948911</td>\n      <td>0.477477</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>4.681500</td>\n      <td>0.116034</td>\n      <td>0.116034</td>\n      <td>0.953843</td>\n      <td>0.518018</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>4.681500</td>\n      <td>0.116917</td>\n      <td>0.116917</td>\n      <td>0.953076</td>\n      <td>0.495495</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>4.681500</td>\n      <td>0.110685</td>\n      <td>0.110685</td>\n      <td>0.957105</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>4.681500</td>\n      <td>0.096908</td>\n      <td>0.096908</td>\n      <td>0.967314</td>\n      <td>0.641892</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>4.681500</td>\n      <td>0.076073</td>\n      <td>0.076073</td>\n      <td>0.969855</td>\n      <td>0.711712</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>4.681500</td>\n      <td>0.090362</td>\n      <td>0.090362</td>\n      <td>0.965499</td>\n      <td>0.650901</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>4.681500</td>\n      <td>0.082501</td>\n      <td>0.082501</td>\n      <td>0.968331</td>\n      <td>0.704955</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>4.681500</td>\n      <td>0.078169</td>\n      <td>0.078169</td>\n      <td>0.972175</td>\n      <td>0.684685</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>4.681500</td>\n      <td>0.069038</td>\n      <td>0.069038</td>\n      <td>0.972341</td>\n      <td>0.745495</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>4.681500</td>\n      <td>0.086951</td>\n      <td>0.086951</td>\n      <td>0.969114</td>\n      <td>0.655405</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>4.681500</td>\n      <td>0.067821</td>\n      <td>0.067821</td>\n      <td>0.974206</td>\n      <td>0.720721</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>4.681500</td>\n      <td>0.069192</td>\n      <td>0.069192</td>\n      <td>0.977274</td>\n      <td>0.736486</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>4.681500</td>\n      <td>0.061274</td>\n      <td>0.061274</td>\n      <td>0.977192</td>\n      <td>0.763514</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>4.681500</td>\n      <td>0.074003</td>\n      <td>0.074003</td>\n      <td>0.976006</td>\n      <td>0.698198</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>4.681500</td>\n      <td>0.043622</td>\n      <td>0.043622</td>\n      <td>0.982288</td>\n      <td>0.849099</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>4.681500</td>\n      <td>0.074530</td>\n      <td>0.074530</td>\n      <td>0.978229</td>\n      <td>0.648649</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>4.681500</td>\n      <td>0.049892</td>\n      <td>0.049892</td>\n      <td>0.981207</td>\n      <td>0.777027</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>4.681500</td>\n      <td>0.076182</td>\n      <td>0.076182</td>\n      <td>0.979227</td>\n      <td>0.646396</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>4.681500</td>\n      <td>0.047590</td>\n      <td>0.047590</td>\n      <td>0.981936</td>\n      <td>0.781532</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>4.681500</td>\n      <td>0.057106</td>\n      <td>0.057106</td>\n      <td>0.980828</td>\n      <td>0.745495</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>4.681500</td>\n      <td>0.057845</td>\n      <td>0.057845</td>\n      <td>0.981547</td>\n      <td>0.743243</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>4.681500</td>\n      <td>0.036341</td>\n      <td>0.036341</td>\n      <td>0.986389</td>\n      <td>0.862613</td>\n    </tr>\n    <tr>\n      <td>101</td>\n      <td>4.681500</td>\n      <td>0.041844</td>\n      <td>0.041844</td>\n      <td>0.985531</td>\n      <td>0.831081</td>\n    </tr>\n    <tr>\n      <td>102</td>\n      <td>4.681500</td>\n      <td>0.042489</td>\n      <td>0.042489</td>\n      <td>0.984794</td>\n      <td>0.817568</td>\n    </tr>\n    <tr>\n      <td>103</td>\n      <td>4.681500</td>\n      <td>0.041799</td>\n      <td>0.041799</td>\n      <td>0.984703</td>\n      <td>0.822072</td>\n    </tr>\n    <tr>\n      <td>104</td>\n      <td>4.681500</td>\n      <td>0.046092</td>\n      <td>0.046092</td>\n      <td>0.986093</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>4.681500</td>\n      <td>0.037731</td>\n      <td>0.037731</td>\n      <td>0.986062</td>\n      <td>0.864865</td>\n    </tr>\n    <tr>\n      <td>106</td>\n      <td>4.681500</td>\n      <td>0.043131</td>\n      <td>0.043130</td>\n      <td>0.985361</td>\n      <td>0.846847</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>4.681500</td>\n      <td>0.035950</td>\n      <td>0.035950</td>\n      <td>0.986188</td>\n      <td>0.878378</td>\n    </tr>\n    <tr>\n      <td>108</td>\n      <td>4.681500</td>\n      <td>0.035420</td>\n      <td>0.035420</td>\n      <td>0.986242</td>\n      <td>0.871622</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>4.681500</td>\n      <td>0.050808</td>\n      <td>0.050807</td>\n      <td>0.983909</td>\n      <td>0.772523</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>4.681500</td>\n      <td>0.037297</td>\n      <td>0.037291</td>\n      <td>0.986273</td>\n      <td>0.864865</td>\n    </tr>\n    <tr>\n      <td>111</td>\n      <td>4.681500</td>\n      <td>0.058498</td>\n      <td>0.058468</td>\n      <td>0.984287</td>\n      <td>0.745495</td>\n    </tr>\n    <tr>\n      <td>112</td>\n      <td>4.681500</td>\n      <td>0.035580</td>\n      <td>0.035560</td>\n      <td>0.987404</td>\n      <td>0.882883</td>\n    </tr>\n    <tr>\n      <td>113</td>\n      <td>4.681500</td>\n      <td>0.053386</td>\n      <td>0.053383</td>\n      <td>0.987508</td>\n      <td>0.783784</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>4.681500</td>\n      <td>0.036305</td>\n      <td>0.036299</td>\n      <td>0.987171</td>\n      <td>0.862613</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>4.681500</td>\n      <td>0.033046</td>\n      <td>0.033033</td>\n      <td>0.988371</td>\n      <td>0.871622</td>\n    </tr>\n    <tr>\n      <td>116</td>\n      <td>4.681500</td>\n      <td>0.034268</td>\n      <td>0.034212</td>\n      <td>0.988276</td>\n      <td>0.864865</td>\n    </tr>\n    <tr>\n      <td>117</td>\n      <td>4.681500</td>\n      <td>0.039505</td>\n      <td>0.039339</td>\n      <td>0.987427</td>\n      <td>0.819820</td>\n    </tr>\n    <tr>\n      <td>118</td>\n      <td>4.681500</td>\n      <td>0.044904</td>\n      <td>0.044778</td>\n      <td>0.986141</td>\n      <td>0.801802</td>\n    </tr>\n    <tr>\n      <td>119</td>\n      <td>4.681500</td>\n      <td>0.025155</td>\n      <td>0.025151</td>\n      <td>0.990050</td>\n      <td>0.948198</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>4.681500</td>\n      <td>0.038713</td>\n      <td>0.038699</td>\n      <td>0.987516</td>\n      <td>0.860360</td>\n    </tr>\n    <tr>\n      <td>121</td>\n      <td>4.681500</td>\n      <td>0.046841</td>\n      <td>0.046782</td>\n      <td>0.985794</td>\n      <td>0.799550</td>\n    </tr>\n    <tr>\n      <td>122</td>\n      <td>4.681500</td>\n      <td>0.047136</td>\n      <td>0.047045</td>\n      <td>0.986476</td>\n      <td>0.801802</td>\n    </tr>\n    <tr>\n      <td>123</td>\n      <td>4.681500</td>\n      <td>0.031510</td>\n      <td>0.031460</td>\n      <td>0.988543</td>\n      <td>0.887387</td>\n    </tr>\n    <tr>\n      <td>124</td>\n      <td>4.681500</td>\n      <td>0.029170</td>\n      <td>0.029160</td>\n      <td>0.989159</td>\n      <td>0.912162</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>4.681500</td>\n      <td>0.031925</td>\n      <td>0.031920</td>\n      <td>0.988532</td>\n      <td>0.891892</td>\n    </tr>\n    <tr>\n      <td>126</td>\n      <td>4.681500</td>\n      <td>0.040924</td>\n      <td>0.040908</td>\n      <td>0.986715</td>\n      <td>0.844595</td>\n    </tr>\n    <tr>\n      <td>127</td>\n      <td>4.681500</td>\n      <td>0.026957</td>\n      <td>0.026906</td>\n      <td>0.989506</td>\n      <td>0.914414</td>\n    </tr>\n    <tr>\n      <td>128</td>\n      <td>4.681500</td>\n      <td>0.030507</td>\n      <td>0.030353</td>\n      <td>0.989152</td>\n      <td>0.900901</td>\n    </tr>\n    <tr>\n      <td>129</td>\n      <td>4.681500</td>\n      <td>0.036444</td>\n      <td>0.036261</td>\n      <td>0.988544</td>\n      <td>0.871622</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>4.681500</td>\n      <td>0.033452</td>\n      <td>0.033164</td>\n      <td>0.988258</td>\n      <td>0.891892</td>\n    </tr>\n    <tr>\n      <td>131</td>\n      <td>4.681500</td>\n      <td>0.029997</td>\n      <td>0.029935</td>\n      <td>0.988368</td>\n      <td>0.898649</td>\n    </tr>\n    <tr>\n      <td>132</td>\n      <td>4.681500</td>\n      <td>0.036313</td>\n      <td>0.036111</td>\n      <td>0.987168</td>\n      <td>0.862613</td>\n    </tr>\n    <tr>\n      <td>133</td>\n      <td>4.681500</td>\n      <td>0.050684</td>\n      <td>0.050270</td>\n      <td>0.985093</td>\n      <td>0.774775</td>\n    </tr>\n    <tr>\n      <td>134</td>\n      <td>4.681500</td>\n      <td>0.026804</td>\n      <td>0.026779</td>\n      <td>0.989390</td>\n      <td>0.936937</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>4.681500</td>\n      <td>0.025700</td>\n      <td>0.025691</td>\n      <td>0.989926</td>\n      <td>0.948198</td>\n    </tr>\n    <tr>\n      <td>136</td>\n      <td>4.681500</td>\n      <td>0.036955</td>\n      <td>0.036888</td>\n      <td>0.988070</td>\n      <td>0.869369</td>\n    </tr>\n    <tr>\n      <td>137</td>\n      <td>4.681500</td>\n      <td>0.035138</td>\n      <td>0.034946</td>\n      <td>0.987900</td>\n      <td>0.871622</td>\n    </tr>\n    <tr>\n      <td>138</td>\n      <td>4.681500</td>\n      <td>0.028540</td>\n      <td>0.028373</td>\n      <td>0.989736</td>\n      <td>0.905405</td>\n    </tr>\n    <tr>\n      <td>139</td>\n      <td>4.681500</td>\n      <td>0.032768</td>\n      <td>0.032642</td>\n      <td>0.989451</td>\n      <td>0.889640</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>4.681500</td>\n      <td>0.030368</td>\n      <td>0.030305</td>\n      <td>0.989097</td>\n      <td>0.905405</td>\n    </tr>\n    <tr>\n      <td>141</td>\n      <td>4.681500</td>\n      <td>0.034646</td>\n      <td>0.034615</td>\n      <td>0.988048</td>\n      <td>0.880631</td>\n    </tr>\n    <tr>\n      <td>142</td>\n      <td>4.681500</td>\n      <td>0.027941</td>\n      <td>0.027916</td>\n      <td>0.989561</td>\n      <td>0.900901</td>\n    </tr>\n    <tr>\n      <td>143</td>\n      <td>0.191500</td>\n      <td>0.035586</td>\n      <td>0.035531</td>\n      <td>0.988178</td>\n      <td>0.876126</td>\n    </tr>\n    <tr>\n      <td>144</td>\n      <td>0.191500</td>\n      <td>0.025461</td>\n      <td>0.025424</td>\n      <td>0.990408</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.191500</td>\n      <td>0.025077</td>\n      <td>0.025047</td>\n      <td>0.990517</td>\n      <td>0.930180</td>\n    </tr>\n    <tr>\n      <td>146</td>\n      <td>0.191500</td>\n      <td>0.031053</td>\n      <td>0.030977</td>\n      <td>0.989135</td>\n      <td>0.889640</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>0.191500</td>\n      <td>0.039268</td>\n      <td>0.039157</td>\n      <td>0.987619</td>\n      <td>0.835586</td>\n    </tr>\n    <tr>\n      <td>148</td>\n      <td>0.191500</td>\n      <td>0.027996</td>\n      <td>0.027972</td>\n      <td>0.989827</td>\n      <td>0.927928</td>\n    </tr>\n    <tr>\n      <td>149</td>\n      <td>0.191500</td>\n      <td>0.031100</td>\n      <td>0.031062</td>\n      <td>0.988987</td>\n      <td>0.912162</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.191500</td>\n      <td>0.026264</td>\n      <td>0.026226</td>\n      <td>0.989875</td>\n      <td>0.930180</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>0.191500</td>\n      <td>0.026969</td>\n      <td>0.026893</td>\n      <td>0.990210</td>\n      <td>0.923423</td>\n    </tr>\n    <tr>\n      <td>152</td>\n      <td>0.191500</td>\n      <td>0.023284</td>\n      <td>0.023206</td>\n      <td>0.991374</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>153</td>\n      <td>0.191500</td>\n      <td>0.032221</td>\n      <td>0.032079</td>\n      <td>0.990687</td>\n      <td>0.907658</td>\n    </tr>\n    <tr>\n      <td>154</td>\n      <td>0.191500</td>\n      <td>0.031937</td>\n      <td>0.031834</td>\n      <td>0.989655</td>\n      <td>0.900901</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.191500</td>\n      <td>0.022231</td>\n      <td>0.022217</td>\n      <td>0.991145</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>0.191500</td>\n      <td>0.032001</td>\n      <td>0.031914</td>\n      <td>0.989597</td>\n      <td>0.909910</td>\n    </tr>\n    <tr>\n      <td>157</td>\n      <td>0.191500</td>\n      <td>0.030601</td>\n      <td>0.030345</td>\n      <td>0.989825</td>\n      <td>0.900901</td>\n    </tr>\n    <tr>\n      <td>158</td>\n      <td>0.191500</td>\n      <td>0.023127</td>\n      <td>0.022946</td>\n      <td>0.991488</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>159</td>\n      <td>0.191500</td>\n      <td>0.026939</td>\n      <td>0.026657</td>\n      <td>0.991225</td>\n      <td>0.945946</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.191500</td>\n      <td>0.021849</td>\n      <td>0.021561</td>\n      <td>0.991619</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>161</td>\n      <td>0.191500</td>\n      <td>0.029924</td>\n      <td>0.029448</td>\n      <td>0.990018</td>\n      <td>0.927928</td>\n    </tr>\n    <tr>\n      <td>162</td>\n      <td>0.191500</td>\n      <td>0.026156</td>\n      <td>0.025868</td>\n      <td>0.990430</td>\n      <td>0.932432</td>\n    </tr>\n    <tr>\n      <td>163</td>\n      <td>0.191500</td>\n      <td>0.026800</td>\n      <td>0.026530</td>\n      <td>0.990209</td>\n      <td>0.921171</td>\n    </tr>\n    <tr>\n      <td>164</td>\n      <td>0.191500</td>\n      <td>0.026452</td>\n      <td>0.026258</td>\n      <td>0.990609</td>\n      <td>0.943694</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.191500</td>\n      <td>0.026989</td>\n      <td>0.026933</td>\n      <td>0.990965</td>\n      <td>0.943694</td>\n    </tr>\n    <tr>\n      <td>166</td>\n      <td>0.191500</td>\n      <td>0.021046</td>\n      <td>0.020999</td>\n      <td>0.991665</td>\n      <td>0.966216</td>\n    </tr>\n    <tr>\n      <td>167</td>\n      <td>0.191500</td>\n      <td>0.022024</td>\n      <td>0.021957</td>\n      <td>0.991568</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>168</td>\n      <td>0.191500</td>\n      <td>0.022504</td>\n      <td>0.022444</td>\n      <td>0.991609</td>\n      <td>0.957207</td>\n    </tr>\n    <tr>\n      <td>169</td>\n      <td>0.191500</td>\n      <td>0.029127</td>\n      <td>0.028913</td>\n      <td>0.990561</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.191500</td>\n      <td>0.029582</td>\n      <td>0.029201</td>\n      <td>0.990620</td>\n      <td>0.918919</td>\n    </tr>\n    <tr>\n      <td>171</td>\n      <td>0.191500</td>\n      <td>0.025026</td>\n      <td>0.024557</td>\n      <td>0.991152</td>\n      <td>0.943694</td>\n    </tr>\n    <tr>\n      <td>172</td>\n      <td>0.191500</td>\n      <td>0.023230</td>\n      <td>0.022763</td>\n      <td>0.991607</td>\n      <td>0.952703</td>\n    </tr>\n    <tr>\n      <td>173</td>\n      <td>0.191500</td>\n      <td>0.021921</td>\n      <td>0.021596</td>\n      <td>0.991603</td>\n      <td>0.961712</td>\n    </tr>\n    <tr>\n      <td>174</td>\n      <td>0.191500</td>\n      <td>0.022543</td>\n      <td>0.022073</td>\n      <td>0.991461</td>\n      <td>0.957207</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.191500</td>\n      <td>0.026925</td>\n      <td>0.026223</td>\n      <td>0.990714</td>\n      <td>0.936937</td>\n    </tr>\n    <tr>\n      <td>176</td>\n      <td>0.191500</td>\n      <td>0.025324</td>\n      <td>0.024624</td>\n      <td>0.991075</td>\n      <td>0.939189</td>\n    </tr>\n    <tr>\n      <td>177</td>\n      <td>0.191500</td>\n      <td>0.026698</td>\n      <td>0.025987</td>\n      <td>0.991000</td>\n      <td>0.943694</td>\n    </tr>\n    <tr>\n      <td>178</td>\n      <td>0.191500</td>\n      <td>0.024559</td>\n      <td>0.024031</td>\n      <td>0.991441</td>\n      <td>0.950450</td>\n    </tr>\n    <tr>\n      <td>179</td>\n      <td>0.191500</td>\n      <td>0.029892</td>\n      <td>0.029332</td>\n      <td>0.990208</td>\n      <td>0.905405</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.191500</td>\n      <td>0.032676</td>\n      <td>0.032175</td>\n      <td>0.989423</td>\n      <td>0.898649</td>\n    </tr>\n    <tr>\n      <td>181</td>\n      <td>0.191500</td>\n      <td>0.025172</td>\n      <td>0.024789</td>\n      <td>0.991004</td>\n      <td>0.943694</td>\n    </tr>\n    <tr>\n      <td>182</td>\n      <td>0.191500</td>\n      <td>0.022614</td>\n      <td>0.022331</td>\n      <td>0.991716</td>\n      <td>0.957207</td>\n    </tr>\n    <tr>\n      <td>183</td>\n      <td>0.191500</td>\n      <td>0.029805</td>\n      <td>0.029518</td>\n      <td>0.991239</td>\n      <td>0.923423</td>\n    </tr>\n    <tr>\n      <td>184</td>\n      <td>0.191500</td>\n      <td>0.023731</td>\n      <td>0.023346</td>\n      <td>0.991432</td>\n      <td>0.954955</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.191500</td>\n      <td>0.021771</td>\n      <td>0.021429</td>\n      <td>0.991762</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>186</td>\n      <td>0.191500</td>\n      <td>0.025202</td>\n      <td>0.024868</td>\n      <td>0.991521</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>187</td>\n      <td>0.191500</td>\n      <td>0.027319</td>\n      <td>0.027078</td>\n      <td>0.990998</td>\n      <td>0.939189</td>\n    </tr>\n    <tr>\n      <td>188</td>\n      <td>0.191500</td>\n      <td>0.020723</td>\n      <td>0.020564</td>\n      <td>0.991785</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>189</td>\n      <td>0.191500</td>\n      <td>0.020365</td>\n      <td>0.020241</td>\n      <td>0.991958</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.191500</td>\n      <td>0.023327</td>\n      <td>0.023183</td>\n      <td>0.991526</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>191</td>\n      <td>0.191500</td>\n      <td>0.025039</td>\n      <td>0.024912</td>\n      <td>0.991377</td>\n      <td>0.948198</td>\n    </tr>\n    <tr>\n      <td>192</td>\n      <td>0.191500</td>\n      <td>0.022131</td>\n      <td>0.022041</td>\n      <td>0.991766</td>\n      <td>0.966216</td>\n    </tr>\n    <tr>\n      <td>193</td>\n      <td>0.191500</td>\n      <td>0.023867</td>\n      <td>0.023746</td>\n      <td>0.991730</td>\n      <td>0.952703</td>\n    </tr>\n    <tr>\n      <td>194</td>\n      <td>0.191500</td>\n      <td>0.024007</td>\n      <td>0.023851</td>\n      <td>0.991704</td>\n      <td>0.950450</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.191500</td>\n      <td>0.024263</td>\n      <td>0.024113</td>\n      <td>0.991386</td>\n      <td>0.945946</td>\n    </tr>\n    <tr>\n      <td>196</td>\n      <td>0.191500</td>\n      <td>0.021267</td>\n      <td>0.021140</td>\n      <td>0.991930</td>\n      <td>0.954955</td>\n    </tr>\n    <tr>\n      <td>197</td>\n      <td>0.191500</td>\n      <td>0.021130</td>\n      <td>0.020930</td>\n      <td>0.991989</td>\n      <td>0.966216</td>\n    </tr>\n    <tr>\n      <td>198</td>\n      <td>0.191500</td>\n      <td>0.019455</td>\n      <td>0.019220</td>\n      <td>0.992440</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>199</td>\n      <td>0.191500</td>\n      <td>0.020748</td>\n      <td>0.020417</td>\n      <td>0.992273</td>\n      <td>0.970721</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.191500</td>\n      <td>0.025429</td>\n      <td>0.024950</td>\n      <td>0.991579</td>\n      <td>0.945946</td>\n    </tr>\n    <tr>\n      <td>201</td>\n      <td>0.191500</td>\n      <td>0.024021</td>\n      <td>0.023530</td>\n      <td>0.991897</td>\n      <td>0.957207</td>\n    </tr>\n    <tr>\n      <td>202</td>\n      <td>0.191500</td>\n      <td>0.022567</td>\n      <td>0.022164</td>\n      <td>0.992256</td>\n      <td>0.966216</td>\n    </tr>\n    <tr>\n      <td>203</td>\n      <td>0.191500</td>\n      <td>0.020585</td>\n      <td>0.020287</td>\n      <td>0.992508</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>204</td>\n      <td>0.191500</td>\n      <td>0.022197</td>\n      <td>0.021934</td>\n      <td>0.991979</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.191500</td>\n      <td>0.022820</td>\n      <td>0.022647</td>\n      <td>0.991545</td>\n      <td>0.968468</td>\n    </tr>\n    <tr>\n      <td>206</td>\n      <td>0.191500</td>\n      <td>0.024023</td>\n      <td>0.023925</td>\n      <td>0.991067</td>\n      <td>0.961712</td>\n    </tr>\n    <tr>\n      <td>207</td>\n      <td>0.191500</td>\n      <td>0.021991</td>\n      <td>0.021909</td>\n      <td>0.991602</td>\n      <td>0.970721</td>\n    </tr>\n    <tr>\n      <td>208</td>\n      <td>0.191500</td>\n      <td>0.021616</td>\n      <td>0.021482</td>\n      <td>0.991924</td>\n      <td>0.966216</td>\n    </tr>\n    <tr>\n      <td>209</td>\n      <td>0.191500</td>\n      <td>0.025868</td>\n      <td>0.025609</td>\n      <td>0.991218</td>\n      <td>0.927928</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.191500</td>\n      <td>0.025855</td>\n      <td>0.025558</td>\n      <td>0.991448</td>\n      <td>0.932432</td>\n    </tr>\n    <tr>\n      <td>211</td>\n      <td>0.191500</td>\n      <td>0.021898</td>\n      <td>0.021666</td>\n      <td>0.992157</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>212</td>\n      <td>0.191500</td>\n      <td>0.018778</td>\n      <td>0.018636</td>\n      <td>0.992706</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>213</td>\n      <td>0.191500</td>\n      <td>0.019003</td>\n      <td>0.018912</td>\n      <td>0.992631</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>0.191500</td>\n      <td>0.020743</td>\n      <td>0.020616</td>\n      <td>0.992337</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.142400</td>\n      <td>0.021140</td>\n      <td>0.020919</td>\n      <td>0.992208</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>0.142400</td>\n      <td>0.020176</td>\n      <td>0.019863</td>\n      <td>0.992328</td>\n      <td>0.966216</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>0.142400</td>\n      <td>0.019328</td>\n      <td>0.019013</td>\n      <td>0.992558</td>\n      <td>0.970721</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>0.142400</td>\n      <td>0.021120</td>\n      <td>0.020750</td>\n      <td>0.992439</td>\n      <td>0.968468</td>\n    </tr>\n    <tr>\n      <td>219</td>\n      <td>0.142400</td>\n      <td>0.023220</td>\n      <td>0.022818</td>\n      <td>0.992114</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.142400</td>\n      <td>0.022435</td>\n      <td>0.022062</td>\n      <td>0.992113</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>221</td>\n      <td>0.142400</td>\n      <td>0.020625</td>\n      <td>0.020303</td>\n      <td>0.992515</td>\n      <td>0.970721</td>\n    </tr>\n    <tr>\n      <td>222</td>\n      <td>0.142400</td>\n      <td>0.020018</td>\n      <td>0.019728</td>\n      <td>0.992648</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>223</td>\n      <td>0.142400</td>\n      <td>0.021302</td>\n      <td>0.021015</td>\n      <td>0.992523</td>\n      <td>0.968468</td>\n    </tr>\n    <tr>\n      <td>224</td>\n      <td>0.142400</td>\n      <td>0.024579</td>\n      <td>0.024151</td>\n      <td>0.992052</td>\n      <td>0.948198</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.142400</td>\n      <td>0.025328</td>\n      <td>0.024784</td>\n      <td>0.991774</td>\n      <td>0.936937</td>\n    </tr>\n    <tr>\n      <td>226</td>\n      <td>0.142400</td>\n      <td>0.024555</td>\n      <td>0.023969</td>\n      <td>0.991722</td>\n      <td>0.943694</td>\n    </tr>\n    <tr>\n      <td>227</td>\n      <td>0.142400</td>\n      <td>0.022268</td>\n      <td>0.021715</td>\n      <td>0.992150</td>\n      <td>0.957207</td>\n    </tr>\n    <tr>\n      <td>228</td>\n      <td>0.142400</td>\n      <td>0.020204</td>\n      <td>0.019686</td>\n      <td>0.992606</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>229</td>\n      <td>0.142400</td>\n      <td>0.021002</td>\n      <td>0.020472</td>\n      <td>0.992380</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.142400</td>\n      <td>0.023311</td>\n      <td>0.022738</td>\n      <td>0.991876</td>\n      <td>0.954955</td>\n    </tr>\n    <tr>\n      <td>231</td>\n      <td>0.142400</td>\n      <td>0.024218</td>\n      <td>0.023644</td>\n      <td>0.991681</td>\n      <td>0.950450</td>\n    </tr>\n    <tr>\n      <td>232</td>\n      <td>0.142400</td>\n      <td>0.024089</td>\n      <td>0.023527</td>\n      <td>0.991736</td>\n      <td>0.952703</td>\n    </tr>\n    <tr>\n      <td>233</td>\n      <td>0.142400</td>\n      <td>0.020602</td>\n      <td>0.020122</td>\n      <td>0.992436</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>234</td>\n      <td>0.142400</td>\n      <td>0.019688</td>\n      <td>0.019239</td>\n      <td>0.992615</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.142400</td>\n      <td>0.019901</td>\n      <td>0.019442</td>\n      <td>0.992564</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>236</td>\n      <td>0.142400</td>\n      <td>0.019491</td>\n      <td>0.019037</td>\n      <td>0.992692</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>237</td>\n      <td>0.142400</td>\n      <td>0.019651</td>\n      <td>0.019159</td>\n      <td>0.992709</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>238</td>\n      <td>0.142400</td>\n      <td>0.020044</td>\n      <td>0.019542</td>\n      <td>0.992668</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>239</td>\n      <td>0.142400</td>\n      <td>0.021372</td>\n      <td>0.020821</td>\n      <td>0.992450</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.142400</td>\n      <td>0.021880</td>\n      <td>0.021362</td>\n      <td>0.992371</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>241</td>\n      <td>0.142400</td>\n      <td>0.022255</td>\n      <td>0.021757</td>\n      <td>0.992326</td>\n      <td>0.968468</td>\n    </tr>\n    <tr>\n      <td>242</td>\n      <td>0.142400</td>\n      <td>0.022723</td>\n      <td>0.022195</td>\n      <td>0.992249</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>243</td>\n      <td>0.142400</td>\n      <td>0.023839</td>\n      <td>0.023240</td>\n      <td>0.992076</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>244</td>\n      <td>0.142400</td>\n      <td>0.024300</td>\n      <td>0.023664</td>\n      <td>0.991992</td>\n      <td>0.959459</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.142400</td>\n      <td>0.023124</td>\n      <td>0.022535</td>\n      <td>0.992167</td>\n      <td>0.963964</td>\n    </tr>\n    <tr>\n      <td>246</td>\n      <td>0.142400</td>\n      <td>0.022037</td>\n      <td>0.021482</td>\n      <td>0.992332</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>247</td>\n      <td>0.142400</td>\n      <td>0.021444</td>\n      <td>0.020936</td>\n      <td>0.992459</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>248</td>\n      <td>0.142400</td>\n      <td>0.020534</td>\n      <td>0.020071</td>\n      <td>0.992644</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>249</td>\n      <td>0.142400</td>\n      <td>0.020267</td>\n      <td>0.019798</td>\n      <td>0.992686</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.142400</td>\n      <td>0.020529</td>\n      <td>0.020025</td>\n      <td>0.992660</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>251</td>\n      <td>0.142400</td>\n      <td>0.020735</td>\n      <td>0.020207</td>\n      <td>0.992637</td>\n      <td>0.977477</td>\n    </tr>\n    <tr>\n      <td>252</td>\n      <td>0.142400</td>\n      <td>0.020936</td>\n      <td>0.020398</td>\n      <td>0.992609</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>253</td>\n      <td>0.142400</td>\n      <td>0.020994</td>\n      <td>0.020455</td>\n      <td>0.992598</td>\n      <td>0.975225</td>\n    </tr>\n    <tr>\n      <td>254</td>\n      <td>0.142400</td>\n      <td>0.021075</td>\n      <td>0.020532</td>\n      <td>0.992578</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>0.142400</td>\n      <td>0.021096</td>\n      <td>0.020554</td>\n      <td>0.992570</td>\n      <td>0.972973</td>\n    </tr>\n    <tr>\n      <td>256</td>\n      <td>0.142400</td>\n      <td>0.021075</td>\n      <td>0.020533</td>\n      <td>0.992571</td>\n      <td>0.972973</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" Submission saved to: /kaggle/working/submission.csv\n         filename     label\n0   audio_706.wav  1.828483\n1   audio_800.wav  2.256455\n2    audio_68.wav  4.376028\n3  audio_1267.wav  3.025353\n4   audio_683.wav  2.594480\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"print(\"hello\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:59:06.830461Z","iopub.execute_input":"2025-04-07T00:59:06.830715Z","iopub.status.idle":"2025-04-07T00:59:06.834984Z","shell.execute_reply.started":"2025-04-07T00:59:06.830693Z","shell.execute_reply":"2025-04-07T00:59:06.834212Z"}},"outputs":[{"name":"stdout","text":"hello\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"### Approach-5","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import BertTokenizer, TrainingArguments, Trainer, BertPreTrainedModel, BertModel\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport torch.nn as nn\n\n\n\n# Convert to HuggingFace datasets\nhf_train_dataset = Dataset.from_pandas(train_df_with_text)\nhf_test_dataset = Dataset.from_pandas(test_df_with_text)\n\n# =============================================\n# 2. Tokenization\n# =============================================\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nhf_train_dataset = hf_train_dataset.map(tokenize, batched=True)\nhf_test_dataset = hf_test_dataset.map(tokenize, batched=True)\n\nhf_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nhf_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# =============================================\n# 3. BERT Model for Regression (Frozen Base)\n# =============================================\nclass BertRegressionModel(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n\n        # Freeze all layers\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n        # Unfreeze last 2 encoder layers + pooler\n        for layer in self.bert.encoder.layer[-2:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        for param in self.bert.pooler.parameters():\n            param.requires_grad = True\n\n        self.regressor = nn.Sequential(\n            nn.Linear(config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        logits = self.regressor(pooled_output).squeeze(-1)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.MSELoss()\n            loss = loss_fn(logits, labels.float())\n\n        return {\"loss\": loss, \"logits\": logits}\n\nmodel = BertRegressionModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n\n# =============================================\n# 4. Metrics (Regression + Accuracy)\n# =============================================\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.flatten()\n    labels = labels.flatten()\n    predictions = np.clip(predictions, 0, 5)\n\n    # Accuracy after rounding to nearest 0.5\n    pred_rounded = np.round(predictions * 2) / 2\n    label_rounded = np.round(labels * 2) / 2\n    accuracy = np.mean(pred_rounded == label_rounded)\n\n    return {\n        \"mse\": mean_squared_error(labels, predictions),\n        \"pearson\": pearsonr(predictions, labels)[0],\n        \"accuracy\": accuracy\n    }\n\n# =============================================\n# 5. Training Arguments\n# =============================================\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=128,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    # load_best_model_at_end=True,\n    # metric_for_best_model=\"pearson\",\n    # greater_is_better=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\n# =============================================\n# 6. Trainer Setup\n# =============================================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=hf_train_dataset,\n    eval_dataset=hf_train_dataset,  # Use validation set if available\n    compute_metrics=compute_metrics,\n)\n\n# =============================================\n# 7. Train the Model\n# =============================================\ntrainer.train()\n\n# # =============================================\n# # 8. Inference on Test Set\n# # =============================================\n# predictions = trainer.predict(hf_test_dataset)\n# predicted_scores = np.clip(predictions.predictions.flatten(), 0, 5)\n\n# # =============================================\n# # 9. Submission File\n# # =============================================\n# submission = pd.DataFrame({\n#     \"filename\": test_df[\"filename\"],\n#     \"label\": predicted_scores\n# })\n\n# submission_path = \"/kaggle/working/submission.csv\"\n# submission.to_csv(submission_path, index=False)\n\n# if os.path.exists(submission_path):\n#     print(f\" Submission saved to: {submission_path}\")\n#     print(submission.head())\n# else:\n#     print(\" Error: Submission file not saved!\")\n\n# =============================================\n# 8. Inference on Test Set (Corrected)\n# =============================================\n\n# 1. First, make sure the test dataset has the right format (only input features)\nhf_test_dataset.set_format(\n    type=\"torch\", \n    columns=[\"input_ids\", \"attention_mask\"]  # No labels needed\n)\n\n# 2. Create a custom prediction function\ndef predict_without_labels(model, dataset):\n    model.eval()\n    predictions = []\n    \n    # Create dataloader\n    dataloader = torch.utils.data.DataLoader(\n        dataset, \n        batch_size=training_args.per_device_eval_batch_size\n    )\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            # Move batch to GPU\n            inputs = {\n                'input_ids': batch['input_ids'].to('cuda'),\n                'attention_mask': batch['attention_mask'].to('cuda')\n            }\n            \n            # Forward pass\n            outputs = model(**inputs)\n            predictions.append(outputs['logits'].cpu().numpy())\n    \n    return np.concatenate(predictions, axis=0)\n\n# 3. Run prediction\npredicted_scores = predict_without_labels(model, hf_test_dataset)\npredicted_scores = np.clip(predicted_scores.flatten(), 0, 5)\n# =============================================\n# 9. Submission File\n# =============================================\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predicted_scores\n})\n\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\n\nif os.path.exists(submission_path):\n    print(f\" Submission saved to: {submission_path}\")\n    print(submission.head())\nelse:\n    print(\" Error: Submission file not saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T01:01:40.716195Z","iopub.execute_input":"2025-04-07T01:01:40.716676Z","iopub.status.idle":"2025-04-07T01:01:40.752013Z","shell.execute_reply.started":"2025-04-07T01:01:40.716645Z","shell.execute_reply":"2025-04-07T01:01:40.750905Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-063e12090174>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Convert to HuggingFace datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhf_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_with_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mhf_test_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df_with_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_df_with_text' is not defined"],"ename":"NameError","evalue":"name 'train_df_with_text' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}